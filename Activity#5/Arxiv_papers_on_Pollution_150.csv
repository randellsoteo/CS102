"","title","author","subject","abstract","meta"
"1","Environmental Insights: Democratizing Access to Ambient Air Pollution Data and Predictive Analytics with an Open-Source Python Package","Liam J Berrisford, Ronaldo Menezes","Physics and Society (physics.soc-ph)","Ambient air pollution is a pervasive issue with wide-ranging effects on human health, ecosystem vitality, and economic structures. Utilizing data on ambient air pollution concentrations, researchers can perform comprehensive analyses to uncover the multifaceted impacts of air pollution across society. To this end, we introduce Environmental Insights, an open-source Python package designed to democratize access to air pollution concentration data. This tool enables users to easily retrieve historical air pollution data and employ a Machine Learning model for forecasting potential future conditions. Moreover, Environmental Insights includes a suite of tools aimed at facilitating the dissemination of analytical findings and enhancing user engagement through dynamic visualizations. This comprehensive approach ensures that the package caters to the diverse needs of individuals looking to explore and understand air pollution trends and their implications.","Wed, 6 Mar 2024 12:34:50 UTC (32,449 KB)"
"2","Bayesian Generalized Distributed Lag Regression with Variable Selection","Daniel Dempsey, Jason Wyse","Methodology (stat.ME)","Distributed Lag Models (DLMs) and similar regression approaches such as MIDAS have been used for many decades in econometrics, and more recently in the study of air quality and its impact on human health. They are useful not only for quantifying accumulating and delayed effects, but also for estimating the lags that are most susceptible to these effects. Among other things, they have been used to infer the period of exposure to poor air quality which might negatively impact child birth weight. The increased attention DLMs have received in recent years is reflective of their potential to help us understand a great many issues, particularly in the investigation of how the environment affects human health. In this paper we describe how to expand the utility of these models for Bayesian inference by leveraging latent-variables. In particular we explain how to perform binary regression to better handle imbalanced data, how to incorporate negative binomial regression, and how to estimate the probability of predictor inclusion. Extra parameters introduced through the DLM framework may require calibration for the MCMC algorithm, but this will not be the case in DLM-based analyses often seen in pollution exposure literature. In these cases, the parameters are inferred through a fully automatic Gibbs sampling procedure.","Wed, 6 Mar 2024 12:10:48 UTC (1,304 KB)"
"3","Learning Zero-Shot Material States Segmentation, by Implanting Natural Image Patterns in Synthetic Data","Sagi Eppel, Jolina Li, Manuel Drehwald, Alan Aspuru-Guzik","Computer Vision and Pattern Recognition (cs.CV)","Visual understanding and segmentation of materials and their states is fundamental for understanding the physical world. The infinite textures, shapes and often blurry boundaries formed by material make this task particularly hard to generalize. Whether it's identifying wet regions of a surface, minerals in rocks, infected regions in plants, or pollution in water, each material state has its own unique form. For neural nets to learn class-agnostic materials segmentation it is necessary to first collect and annotate data that capture this complexity. Collecting real-world images and manually annotating is limited both by the cost and limited precision of manual labor. In contrast, synthetic data is highly accurate and almost cost-free but fails to replicate the vast diversity of the material world. In this work, we suggest a method to bridge this crucial gap, by implanting patterns extracted from real-world images, in synthetic data. Hence, patterns automatically collected from natural images are used to map materials into synthetic scenes. This unsupervised approach allows the generated data to capture the vast complexity of the real world while maintaining the precision and scale of synthetic data. We also present the first general benchmark for class-agnostic material state segmentation. The benchmark images contain a wide range of real-world images of material states, from cooking, food, rocks, construction, plants, and liquids each in various states (wet/dry/stained/cooked/burned/worned/rusted/sediment/foam...). The annotation includes both partial similarity between regions with similar but not identical materials, and hard segmentation of only points of the exact same material state. We show that net trains on MatSeg significantly outperform existing state-of-the-art methods on this task.","Tue, 5 Mar 2024 20:21:49 UTC (5,119 KB)[v2] Thu, 7 Mar 2024 17:43:54 UTC (4,533 KB)"
"4","From Displacements to Distributions: A Machine-Learning Enabled Framework for Quantifying Uncertainties in Parameters of Computational Models","Taylor Roper, Harri Hakula, Troy Butler","Machine Learning (stat.ML)","This work presents novel extensions for combining two frameworks for quantifying both aleatoric (i.e., irreducible) and epistemic (i.e., reducible) sources of uncertainties in the modeling of engineered systems. The data-consistent (DC) framework poses an inverse problem and solution for quantifying aleatoric uncertainties in terms of pullback and push-forward measures for a given Quantity of Interest (QoI) map. Unfortunately, a pre-specified QoI map is not always available a priori to the collection of data associated with system outputs. The data themselves are often polluted with measurement errors (i.e., epistemic uncertainties), which complicates the process of specifying a useful QoI. The Learning Uncertain Quantities (LUQ) framework defines a formal three-step machine-learning enabled process for transforming noisy datasets into samples of a learned QoI map to enable DC-based inversion. We develop a robust filtering step in LUQ that can learn the most useful quantitative information present in spatio-temporal datasets. The learned QoI map transforms simulated and observed datasets into distributions to perform DC-based inversion. We also develop a DC-based inversion scheme that iterates over time as new spatial datasets are obtained and utilizes quantitative diagnostics to identify both the quality and impact of inversion at each iteration. Reproducing Kernel Hilbert Space theory is leveraged to mathematically analyze the learned QoI map and develop a quantitative sufficiency test for evaluating the filtered data. An illustrative example is utilized throughout while the final two examples involve the manufacturing of shells of revolution to demonstrate various aspects of the presented frameworks.","Mon, 4 Mar 2024 20:40:50 UTC (5,324 KB)"
"5","Double-mixing CP violation in $B$ decays","Wen-Jie Song, Yin-Fa Shen, Qin Qin","High Energy Physics - Phenomenology (hep-ph)","We study a long-overlooked CP violation observable, termed double-mixing CP violation, which arises from the interference between two neutral meson oscillating paths involved in a decay chain. The double-mixing CP violation is beneficial for the precise test of the Standard Model CKM mechanism, as it offers the potential to extract weak phases without pollution from strong dynamics. To provide a comprehensive understanding of the double-mixing CP violation, we perform phenomenological analyses on the cascade decays of the $B^0_d$ and $B^0_s$ mesons. Our results show that the double-mixing CP violation can be very significant in certain decay channels, such as $B^0_s \to \rho^0 K \to \rho^0(\pi^-\ell^+\nu_\ell)$. In addition, we employ the decay process $B^0_d \to D^0 K \to (K^-\pi^+)(\pi\ell\nu)$ to demonstrate that the involved strong and weak phases can be directly determined from the experimental data without any theoretical inputs.","Mon, 4 Mar 2024 10:05:47 UTC (13,518 KB)"
"6","Optimization of the Energy-Comfort Trade-Off of HVAC Systems in Electric City Buses Based on a Steady-State Model","Fabio Widmer, Stijn van Dooren, Christopher H. Onder","Systems and Control (eess.SY)","The electrification of public transport vehicles offers the potential to relieve city centers of pollutant and noise emissions. Furthermore, electric buses have lower life-cycle greenhouse gas (GHG) emissions than diesel buses, particularly when operated with sustainably produced electricity. However, the heating, ventilation, and air-conditioning (HVAC) system can consume a significant amount of energy, thus limiting the achievable driving range. In this paper, we address the HVAC system in an electric city bus by analyzing the trade-off between the energy consumption and the thermal comfort of the passengers. We do this by developing a dynamic thermal model for the bus cabin, which we simplify by considering it to be in steady state. We introduce a method that is able to quickly optimize the steady-state HVAC system inputs for a large number of samples representative of a year-round operation. A comparison between the results from the steady-state optimization approach and a dynamic simulation reveal small deviations in both the HVAC system power demand and achieved thermal comfort. Thus, the approximation of the system performance with a steady-state model is justified. We present two case studies to demonstrate the practical relevance of the approach. First, we show how the method can be used to compare different system designs based on a year-round performance evaluation. Second, we show how the method can be used to generate accurate setpoints for online controllers. In conclusion, this study shows that a steady-state analysis of the HVAC systems of an electric city bus is a valuable approach to evaluate and optimize its performance.","Fri, 1 Mar 2024 13:28:52 UTC (2,380 KB)"
"7","Prices and preferences in the electric vehicle market","Chung Yi See, Vasco Rato Santos, Lucas Woodley, Megan Yeo, Daniel Palmer, Shuheng Zhang, and Ashley Nunes","Econometrics (econ.EM)","Although electric vehicles are less polluting than gasoline powered vehicles, adoption is challenged by higher procurement prices. Existing discourse emphasizes EV battery costs as being principally responsible for this price differential and widespread adoption is routinely conditioned upon battery costs declining. We scrutinize such reasoning by sourcing data on EV attributes and market conditions between 2011 and 2023. Our findings are fourfold. First, EV prices are influenced principally by the number of amenities, additional features, and dealer-installed accessories sold as standard on an EV, and to a lesser extent, by EV horsepower. Second, EV range is negatively correlated with EV price implying that range anxiety concerns may be less consequential than existing discourse suggests. Third, battery capacity is positively correlated with EV price, due to more capacity being synonymous with the delivery of more horsepower. Collectively, this suggests that higher procurement prices for EVs reflects consumer preference for vehicles that are feature dense and more powerful. Fourth and finally, accommodating these preferences have produced vehicles with lower fuel economy, a shift that reduces envisioned lifecycle emissions benefits by at least 3.26 percent, subject to the battery pack chemistry leveraged and the carbon intensity of the electrical grid. These findings warrant attention as decarbonization efforts increasingly emphasize electrification as a pathway for complying with domestic and international climate agreements.","Fri, 1 Mar 2024 11:30:25 UTC (1,569 KB)"
"8","Assessing light pollution in vast areas: zenith sky brightness maps of Catalonia","Hector Linares, Eduard Masana Salvador J Ribas, Manuel García-Gil, Martin Aubé, Alejandro Sánchez de Miguel, Alexandre Simoneau","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Zenith sky brightness maps in the V and B bands of the region of Catalonia are presented in this paper. For creating them we have used the light pollution numerical model Illumina v2. The maps have a sampling of 5x5 km for the whole region with an improved resolution of 1x1 km for one of the provinces within Catalonia, Tarragona. Before creating the final maps, the methodology was tested successfully by comparing the computed values to measurements in nineteen different locations spread out throughout the territory. The resulting maps have been compared to the zenith sky brightness world atlas and also to Sky Quality Meter (SQM) dynamic measurements. When comparing to measurements we found small differences mainly due to mismatching in the location of the points studied, and also due to differences in the natural sky brightness and atmospheric content. In the comparison to the world atlas some differences were expected as we are taking into account the blocking effect of topography and obstacles, and also due to a more precise light sources characterization. The results of this work confirm the conclusion found in other studies that the minimum sampling for studying sky brightness fine details is of 1x1 km. However, a sampling of 5x5 km is interesting when studying general trends, mainly for vast areas, due to the reduction of the time required to create the maps.","Thu, 29 Feb 2024 20:30:46 UTC (20,808 KB)"
"9","Abundances of Neutron-Capture Elements in 62 Stars in the Globular Cluster Messier 15","Jonathan Cabrera Garcia, Charli M. Sakari, Ian U. Roederer, Donavon W. Evans, Pedro Silva, Mario Mateo, Ying-Yi Song, Anthony Kremin, John I. Bailey III, Matthew G. Walker","Solar and Stellar Astrophysics (astro-ph.SR)","M15 is a globular cluster with a known spread in neutron-capture elements. This paper presents abundances of neutron-capture elements for 62 stars in M15. Spectra were obtained with the Michigan/Magellan Fiber System (M2FS) spectrograph, covering a wavelength range from ~4430-4630 A. Spectral lines from Fe I, Fe II, Sr I, Zr II, Ba II, La II, Ce II, Nd II, Sm II, Eu II, and Dy II, were measured, enabling classifications and neutron-capture abundance patterns for the stars. Of the 62 targets, 44 are found to be highly Eu-enhanced r-II stars, another 17 are moderately Eu-enhanced r-I stars, and one star is found to have an s-process signature. The neutron-capture patterns indicate that the majority of the stars are consistent with enrichment by the r-process. The 62 target stars are found to show significant star-to-star spreads in Sr, Zr, Ba, La, Ce, Nd, Sm, Eu, and Dy, but no significant spread in Fe. The neutron-capture abundances are further found to have slight correlations with sodium abundances from the literature, unlike what has been previously found; follow-up studies are needed to verify this result. The findings in this paper suggest that the Eu-enhanced stars in M15 were enhanced by the same process, that the nucleosynthetic source of this Eu pollution was the r-process, and that the r-process source occurred as the first generation of cluster stars was forming.","Thu, 29 Feb 2024 19:00:10 UTC (361 KB)"
"10","Airport take-off and landing optimization through genetic algorithms","Fernando Guedan Pecker, Cristian Ramirez Atencia","Neural and Evolutionary Computing (cs.NE)","This research addresses the crucial issue of pollution from aircraft operations, focusing on optimizing both gate allocation and runway scheduling simultaneously, a novel approach not previously explored. The study presents an innovative genetic algorithm-based method for minimizing pollution from fuel combustion during aircraft take-off and landing at airports. This algorithm uniquely integrates the optimization of both landing gates and take-off/landing runways, considering the correlation between engine operation time and pollutant levels. The approach employs advanced constraint handling techniques to manage the intricate time and resource limitations inherent in airport operations. Additionally, the study conducts a thorough sensitivity analysis of the model, with a particular emphasis on the mutation factor and the type of penalty function, to fine-tune the optimization process. This dual-focus optimization strategy represents a significant advancement in reducing environmental impact in the aviation sector, establishing a new standard for comprehensive and efficient airport operation management.","Thu, 29 Feb 2024 14:53:55 UTC (6,764 KB)"
"11","Chemical Diagnostics to Unveil Environments Enriched by First Stars","Irene Vanni, Stefania Salvadori, Valentina D'Odorico, George D. Becker, Guido Cupani","Astrophysics of Galaxies (astro-ph.GA)","Unveiling the chemical fingerprints of the first (Pop III) stars is crucial for indirectly studying their properties and probing their massive nature. In particular, very massive Pop III stars explode as energetic Pair-Instability Supernovae (PISNe), so their chemical products might escape in the diffuse medium around galaxies, opening the possibility to observe their fingerprints in distant gas clouds. Recently, three z > 6.3 absorbers with abundances consistent with an enrichment from PISNe have been observed with JWST. In this Letter, we present novel chemical diagnostics to uncover environments mainly imprinted by PISNe. Furthermore, we revise the JWST low-resolution measurements by analysing the publicly available high-resolution X-Shooter spectra for two of these systems. Our results reconcile the chemical abundances of these absorbers with those from literature, which are found to be consistent with an enrichment dominated (> 50% metals) by normal Pop II SNe. We show the power of our novel diagnostics in isolating environments uniquely enriched by PISNe from those mainly polluted by other Pop III and Pop II SNe. When the subsequent enrichment from Pop II SNe is included, however, we find that the abundances of PISN-dominated environments partially overlap with those predominantly enriched by other Pop III and Pop II SNe. We dub these areas confusion regions. Yet, the odd-even abundance ratios [Mg,Si/Al] are extremely effective in pinpointing PISNedominated environments and allowed us to uncover, for the first time, an absorber consistent with a PISN enrichment for all the six measured elements.","Wed, 28 Feb 2024 19:00:04 UTC (2,314 KB)"
"12","Note: Evolutionary Game Theory Focus Informational Health: The Cocktail Party Effect Through Werewolfgame under Incomplete Information and ESS Search Method Using Expected Gains of Repeated Dilemmas","Yasuko Kawahata","Physics and Society (physics.soc-ph)","We explore the state of information disruption caused by the cocktail party effect within the framework of non-perfect information games and evolutive games with multiple werewolves. In particular, we mathematically model and analyze the effects on the gain of each strategy choice and the formation process of evolutionary stable strategies (ESS) under the assumption that the pollution risk of fake news is randomly assigned in the context of repeated dilemmas. We will develop the computational process in detail, starting with the construction of the gain matrix, modeling the evolutionary dynamics using the replicator equation, and identifying the ESS. In addition, numerical simulations will be performed to observe system behavior under different initial conditions and parameter settings to better understand the impact of the spread of fake news on strategy evolution. This research will provide theoretical insights into the complex issues of contemporary society regarding the authenticity of information and expand the range of applications of evolutionary game theory.","Tue, 27 Feb 2024 14:10:34 UTC (3,851 KB)"
"13","Token-based Vehicular Security System (TVSS): Scalable, Secure, Low-latency Public Key Infrastructure for Connected Vehicles","Abdulrahman Bin Rabiah, Anas Alsoliman, Yugarshi Shashwat, Silas Richelson, Nael Abu-Ghazaleh","Cryptography and Security (cs.CR)","Connected and Autonomous vehicles stand to drastically improve the safety and efficiency of the transportation system in the near future while also reducing pollution. These systems leverage communication to coordinate among vehicles and infrastructure in service of a number of safety and efficiency driver assist and even fully autonomous applications. Attackers can compromise these systems in a number of ways including by falsifying communication messages, making it critical to support security mechanisms that can operate and scale in dynamic scenarios. Towards this end, we present TVSS, a new VPKI system which improves drastically over prior work in the area (including over SCMS; the US department of transportation standard for VPKI). TVSS leverages the idea of unforgeable tokens to enable rapid verification at the road side units (RSUs), which are part of the road infrastructure at the edge of the network. This edge based solution enables agile authentication by avoiding the need for back-end servers during the potentially short contact time between a moving vehicle and the infrastructure. It also results in several security advantages: (1) Scalable Revocation: it greatly simplifies the revocation problem, a difficult problem in large scale certificate systems; and (2) Faster Refresh: Vehicles interact more frequently with the system to refresh their credentials, improving the privacy of the system. We provide a construction of the system and formally prove its security. Field experiments on a test-bed we develop consisting of on-board units (OBUs) and RSUs shows substantial reduction in the latency of refreshing credentials compared to SCMS, allowing the system to work even with smaller window of connectivity when vehicles are moving at higher speeds. Notably, we are able to execute the bottleneck operation of our scheme with a stationary RSU while traveling at highway speeds .","Wed, 28 Feb 2024 14:35:52 UTC (8,916 KB)"
"14","Oil Spill Drone: A Dataset of Drone-Captured, Segmented RGB Images for Oil Spill Detection in Port Environments","T. De Kerf, S. Sels, S. Samsonova, S. Vanlanduit","Computer Vision and Pattern Recognition (cs.CV)","The high incidence of oil spills in port areas poses a serious threat to the environment, prompting the need for efficient detection mechanisms. Utilizing automated drones for this purpose can significantly improve the speed and accuracy of oil spill detection. Such advancements not only expedite cleanup operations, reducing environmental harm but also enhance polluter accountability, potentially deterring future incidents. Currently, there's a scarcity of datasets employing RGB images for oil spill detection in maritime settings. This paper presents a unique, annotated dataset aimed at addressing this gap, leveraging a neural network for analysis on both desktop and edge computing platforms. The dataset, captured via drone, comprises 1268 images categorized into oil, water, and other, with a convolutional neural network trained using an Unet model architecture achieving an F1 score of 0.71 for oil detection. This underscores the dataset's practicality for real-world applications, offering crucial resources for environmental conservation in port environments.","Wed, 28 Feb 2024 09:47:35 UTC (339 KB)"
"15","Cosmic Type Ia SN rate and constraints on SN Ia progenitors","P.A. Palicio, F. Matteucci, M. Della Valle, E. Spitoni","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Type Ia supernovae play a key role in the evolution of galaxies by polluting the interstellar medium with a fraction of iron peak elements larger than that released in the core collapse supernova events. Their light-curve, moreover, is widely used in cosmological studies as it constitutes a reliable distance indicator at extra-galactic scales. Among the mechanisms proposed to explain the Type Ia SNe, the single and double degenerate channels are thought to be the dominant ones, which imply a different distribution of time delays between the progenitor formation and the explosion. In this paper, we aim at determining the dominant mechanism by comparing a compilation of observed type Ia SN with our predictions, and evaluating the relative contribution of both channels. By using a least-squares fitting procedure, we model the observations of type Ia SN rates assuming different combinations of three recent cosmic star formation rates and seven delay time distributions. The goodness of these fits are statistically quantified by the chi-squared test. Though dependent on the assumed cosmic star formation rate, we find arguments in favor of the single degenerate model. From the theoretic point of view, at least the sim 30% of the Type Ia SN must have been produced through the single degenerate channel to account for the observations. The wide double degenerate scenario mechanism slightly under-predicts the observations at redshift z>1, unless the cosmic SFR flattens in that regime. On the contrary, although the purely close double degenerate scenario can be ruled out, we cannot rule out a mixed scenario with single and double degenerate progenitors.","Mon, 26 Feb 2024 15:05:06 UTC (2,550 KB)"
"16","Discovery of magnetically guided metal accretion onto a polluted white dwarf","S. Bagnulo, J. Farihi, J.D. Landstreet, C. Folsom","Solar and Stellar Astrophysics (astro-ph.SR)","Dynamically active planetary systems orbit a significant fraction of white dwarf stars. These stars often exhibit surface metals accreted from debris disks, which are detected through infrared excess or transiting structures. However, the full journey of a planetesimal from star-grazing orbit to final dissolution in the host star is poorly understood. Here, we report the discovery that the cool metal polluted star WD0816-310 has cannibalized heavy elements from a planetary body similar in size to Vesta, and where accretion and horizontal mixing processes have clearly been controlled by the stellar magnetic field. Our observations unveil periodic and synchronized variations in metal line strength and magnetic field intensity, implying a correlation between the local surface density of metals and the magnetic field structure. Specifically, the data point to a likely persistent concentration of metals near a magnetic pole. These findings demonstrate that magnetic fields may play a fundamental role in the final stages of exoplanetary bodies that are recycled into their white dwarf hosts.","Mon, 26 Feb 2024 12:17:57 UTC (416 KB)"
"17","A Stationary Equilibrium Model of Green Technology Adoption with Endogenous Carbon Price","Felix Dammann, Giorgio Ferrari","Mathematical Finance (q-fin.MF)","This paper proposes and analyzes a stationary equilibrium model for a competitive industry which endogenously determines the carbon price necessary to achieve a given emission target. In the model, firms are identified by their level of technology and make production, entry, and abatement decisions. Polluting firms are subject to a carbon price and abatement is formulated as an irreversible investment, which entails a sunk cost and results in the firms switching to a carbon neutral technology. In equilibrium, we identify a carbon price and a stationary distribution of incumbent, polluting firms, that guarantee the compliance with a certain emission target. Our general theoretical framework is complemented with a case study with Brownian technology shocks, in which we discuss some implications of our model. We observe that a carbon pricing system alongside installation subsidies and tax benefits for green firms trigger earlier investment, while higher income taxes for polluting firms may be distorting. Moreover, we discuss the role of a welfare maximizing regulator, who, by optimally setting the emission target, may mitigate or revert some parameters' effects observed in the model with fixed limit.","Mon, 26 Feb 2024 08:53:29 UTC (279 KB)"
"18","Effect of temperature and copper doping on the heterogeneous Fenton-like activity of Cu$_x$Fe$_{3-x}$O$_4$ nanoparticles","Nahuel Nuñez, Enio Lima Jr., Marcelo Vásquez Mansilla, Gerardo F. Goya, Álvaro Gallo-Cordova, María del Puerto Morales, Elin L. Winkler","Materials Science (cond-mat.mtrl-sci)","Ferrite nanoparticles serve as potent heterogeneous Fenton-like catalysts, producing reactive oxygen species (ROS) for decomposing organic pollutants. We investigated the impact of temperature and copper content on the catalytic activity of nanoparticles with different oxidation states of iron. Via solvothermal synthesis, we fabricated copper-doped magnetite (Cu$_x$Fe$_{3-x}$O$_4$) with a Fe$^{2+}$/Fe ratio ~0.33 for the undoped system. Using a microwave-assisted method, we produced copper-doped oxidized ferrites, yielding a Fe$^{2+}$/Fe ratio of ~0.11 for the undoped nanoparticles. The ROS generated by the catalyst were identified and quantified by electron paramagnetic resonance, while optical spectroscopy allowed us to evaluate its effectiveness for the degradation of a model organic dye. At room temperature, the magnetite nanoparticles exhibited the most $\cdot$OH radical production and achieved almost 90% dye discoloration in 2 hours. This efficiency decreased with increasing Cu concentration, concurrently with a decrease in $\cdot$OH generation. Conversely, above room temperature, Cu-doped nanoparticles significantly enhance the dye degradation, reaching 100% discoloration at 90$^\circ$C. This enhancement is accompanied by a systematic increase in the kinetic constants, obtained from reaction equations, with Cu doping. This study highlights the superior stability and high-temperature catalytic advantages of copper ferrite holding promise for enhancing the performance of nanocatalysts for decomposing organic contaminants.","Fri, 23 Feb 2024 14:19:10 UTC (2,447 KB)"
"19","High-resolution spectroscopic analysis of four unevolved barium stars","M. P. Roriz, N. Holanda, L. V. da Conceição, S. Junqueira, N. A. Drake, A. Sonally, C. B. Pereira","Solar and Stellar Astrophysics (astro-ph.SR)","A classical Local Thermodynamic Equilibrium analysis, based on high-resolution spectroscopic data, is performed for a sample of three potential barium dwarf candidates and one star already recognized as such. We derived their atmospheric parameters, estimated their masses and luminosities, and determined chemical abundances for a set of 21 elements, including CNO. Some elemental abundances are derived for the first time in HD~15096, HD~37792, and HD~141804. The program stars are dwarfs/subgiants with metallicities typical of disc stars, exhibiting moderate carbon enhancements, with $\rm{[C/Fe]}$ ratios ranging from $+0.29$ to $+0.66$ dex, and high levels of \textit{slow} neutron-capture ($s$-process) elements, with $\rm{[\textit{s}/Fe]}\gtrsim +1.0$~dex. As spectroscopic binaries, their peculiarities are attributable to mass transfer events. The observed neutron-capture patterns of were individually compared with two sets of $s$-process nucleosynthesis models (Monash and {\sc fruity}), yielding dilution factors and masses estimates for the former polluting Asymptotic Giant Branch stars. Low-mass ($\lesssim 3.0~\rm{M}_{\odot}$) models successfully reproduce the observations. In addition, we estimated mean neutron exposures of the order of 0.6 -- 0.7 mb$^{-1}$ for the $s$-processed material observed in their envelopes. Applying an empirical initial-final mass relation, we constraint in $\sim 0.7\,\textrm{M}_{\odot}$ the mass of their dim white-dwarf companions. Moreover, our kinematic study revealed that the program stars are members of the thin disk, with probabilities greater than 70\%. Hence, we identified HD~15096 and HD~37792 as new barium dwarfs and confirmed that HD~141804 is a barium dwarf. Thus, the number of barium dwarfs identified in the literature from high-resolution spectroscopy increases to 71 objects.","Thu, 22 Feb 2024 17:10:07 UTC (397 KB)[v2] Fri, 23 Feb 2024 19:15:20 UTC (388 KB)"
"20","Big data analytics to classify earthwork-related locations: A Chengdu study","Lei Yu, Ke Han","Machine Learning (cs.LG)","Air pollution has significantly intensified, leading to severe health consequences worldwide. Earthwork-related locations (ERLs) constitute significant sources of urban dust pollution. The effective management of ERLs has long posed challenges for governmental and environmental agencies, primarily due to their classification under different regulatory authorities, information barriers, delays in data updating, and a lack of dust suppression measures for various sources of dust pollution. To address these challenges, we classified urban dust pollution sources using dump truck trajectory, urban point of interest (POI), and land cover data. We compared several prediction models and investigated the relationship between features and dust pollution sources using real data. The results demonstrate that high-accuracy classification can be achieved with a limited number of features. This method was successfully implemented in the system called Alpha MAPS in Chengdu to provide decision support for urban pollution control.","Thu, 22 Feb 2024 16:50:32 UTC (4,520 KB)"
"21","Offshoring Emissions through Used Vehicle Exports","S.J. Newman, K. Schulte, M.M. Morellini, C. Rahal, D. Leasure","General Economics (econ.GN)","Policies to reduce transport emissions often overlook the international flow of used vehicles. We quantify the rate at which used vehicles generated CO2 and pollution for all used vehicles exported from Great Britain; a globally leading used vehicle exporter across 2005-2021. Destined for low-middle-income countries, exported vehicles fail roadworthiness standards and, even under extremely optimistic functioning as new assumptions, generate at least 13-53 percent more emissions than scrapped or on-road vehicles.","Wed, 21 Feb 2024 13:44:59 UTC (1,033 KB)"
"22","Scalable Methods for Brick Kiln Detection and Compliance Monitoring from Satellite Imagery: A Deployment Case Study in India","Rishabh Mondal, Zeel B Patel, Vannsh Jani, Nipun Batra","Computer Vision and Pattern Recognition (cs.CV)","Air pollution kills 7 million people annually. Brick manufacturing industry is the second largest consumer of coal contributing to 8%-14% of air pollution in Indo-Gangetic plain (highly populated tract of land in the Indian subcontinent). As brick kilns are an unorganized sector and present in large numbers, detecting policy violations such as distance from habitat is non-trivial. Air quality and other domain experts rely on manual human annotation to maintain brick kiln inventory. Previous work used computer vision based machine learning methods to detect brick kilns from satellite imagery but they are limited to certain geographies and labeling the data is laborious. In this paper, we propose a framework to deploy a scalable brick kiln detection system for large countries such as India and identify 7477 new brick kilns from 28 districts in 5 states in the Indo-Gangetic plain. We then showcase efficient ways to check policy violations such as high spatial density of kilns and abnormal increase over time in a region. We show that 90% of brick kilns in Delhi-NCR violate a density-based policy. Our framework can be directly adopted by the governments across the world to automate the policy regulations around brick kilns.","Wed, 21 Feb 2024 13:26:00 UTC (26,263 KB)"
"23","Photon Classification with Gradient Boosted Trees at CLAS12","Gregory Matousek, Anselm Vossen","High Energy Physics - Experiment (hep-ex)","Dihadron semi-inclusive deep inelastic scattering (SIDIS) of 10.6 GeV longitudinally polarized electrons off the proton has been measured using the CLAS12 detector at Jefferson Lab. Two separate channels, $\pi^+\pi^0$ and $\pi^-\pi^0$, were analyzed, requiring the reconstruction of diphoton pairs. In this analysis, we addressed the problem of false neutral particles being reconstructed by CLAS12's event builder, polluting the otherwise physical combinatorial background underneath the $\pi^0$ peak. A photon classifier using a Gradient Boosted Trees (GBTs) architecture was trained with Monte Carlo simulations to reduce the amount of background $\pi^0$'s. We show that the nearest-neighbor features learned by the model lead to a substantial increase in signal vs. background discrimination compared to previous CLAS12 $\pi^0$ analyses. The machine learning approach recovers several times more dihadron statistics for the dataset.","Tue, 20 Feb 2024 16:00:41 UTC (1,534 KB)"
"24","Experimental study of aerosol deposition in distal lung bronchioles","Arnab Kumar Mallik","Fluid Dynamics (physics.flu-dyn)","The deposition of micron particles finds importance in meteorology and several engineering applications such as deposition of dust in gas lines, carbon deposition in engine exhaust, designing effective air-cleaning systems and estimating deposition of inhaled drug or atmospheric pollutants to determine its consequences on human health. Although the existing literature on deposition in straight tubes is quite mature, an experimental study on deposition in micro capillaries with a wide ranges of Re that models particle dynamics in lungs, is missing. The deposition of atmospheric pollutants and nebulized drugs in the lung depends on various biological factors such as flow properties, lung morphology, breathing patterns, particle properties, deposition mechanism, etc. To complicate matters, each breath manifests flows spanning a wide range of Reynolds numbers in various regions of the lung. In this study, the deposition of nebulized aerosol was experimentally investigated in phantom bronchioles of diameters relevant to the 7th to the 23rd branching generations and over the entire range of Re manifest during one breathing cycle. The aerosol fluid was loaded with boron doped carbon quantum dots as a fluorophore. An aerosol was generated of this mixture fluid using an ultrasonic nebulizer, producing droplets of 6.5$\mu$m as the mean diameter. The amount of aerosol deposited on the bronchiole walls was measured using a spectrofluorometer. Finally, a universal bronchiole scale deposition model is proposed which can form the building block for lung-scale aerosol deposition prediction.","Mon, 19 Feb 2024 16:59:26 UTC (7,363 KB)"
"25","PureNav: A Personalized Navigation Service for Environmental Justice Communities Impacted by Planned Disruptions","Omar Hammad, Md Rezwanur Rahman, Nicholas Clements, Shivakant Mishra, Shelly Miller, Esther Sullivan","Social and Information Networks (cs.SI)","Planned disruptions such as highway constructions are commonplace nowadays and the communities living near these disruptions generally tend to be environmental justice communities -- low socioeconomic status with disproportionately high and adverse human health and environmental effects. A major concern is that such activities negatively impact people's well-being by disrupting their daily commutes via frequent road closures and increased dust and air pollution. This paper addresses this concern by developing a personalized navigation service called PureNav to mitigate the negative impacts of disruptions in daily commutes on people's well-being. PureNav has been designed using active engagement with four environmental justice communities affected by major highway construction. It has been deployed in the real world among the members of the four communities, and a detailed analysis of the data collected from this deployment as well as surveys show that PureNav is potentially useful in improving people's well-being. The paper describes the design, implementation, and evaluation of PureNav, and offers suggestions for further improving its efficacy.","Sat, 17 Feb 2024 03:29:20 UTC (6,086 KB)"
"26","Investigating black hole accretion disks as potential polluter sources for the formation of enriched stars in globular clusters","Laurane Fréour, Alice Zocchi, Glenn van de Ven, Elena Pancino","Astrophysics of Galaxies (astro-ph.GA)","Accretion disks surrounding stellar mass black holes (BHs) have been suggested as potential locations for the nucleosynthesis of light elements, which are our primary observational discriminant of multiple stellar populations within globular clusters. The population of enriched stars in globular clusters are enhanced in N14, Na23, and sometimes in Al27 and/or in K39. In this study, our aim is to investigate the feasibility of initiating nucleosynthesis for these four elements in BH accretion disks, considering various internal parameters such as the temperature of the gas and timescale of the accretion. To achieve this, we employed a 132-species reaction network. We used the slim disk model, suitable for the Super-Eddington mass accretion rate and for geometrically and optically thick disks. We explored the conditions related to the mass, mass accretion rate, viscosity, and radius of the BH-accretion disk system that would allow for the creation of N14, Na23, Al27, and K39 before the gas is accreted onto the central object. Our findings reveal that there is no region in the parameter space where the formation of Na23 can occur and only a very limited region where the formation of N14, Al27, and K39 is plausible. Specifically, this occurs for BHs with masses lower than 10 solar masses, with a preference toward even lower mass values and extremely low viscosity parameters ($\alpha <10^{-3}$). Such values are highly unlikely based on current observations of stellar mass BHs. However, such low mass BHs could actually exist in the early universe, as so-called primordial BHs. In conclusion, our study suggests that the nucleosynthesis within BH accretion disks of four elements of interest for the multiple stellar populations is improbable, but not impossible, using the slim disk model.","Fri, 16 Feb 2024 11:23:40 UTC (1,427 KB)"
"27","The affect of Some Meteorological Parameters on Particulate Matters Concentration Over Iraq using Remote Sensing dataset","Sabah Hussein Ali, Amina Basil Mohammed","Atmospheric and Oceanic Physics (physics.ao-ph)","Numerous countries have built urban stations for monitoring the amount of PM2.5 in the atmosphere. In Iraq, there aren't enough stations to monitor PM2.5 pollution levels across all governorates. As a result, satellite remote sensing data is used in the majority of studies aimed at monitoring PM2.5 and the impact of other factors on it. The current study aimed to analyze the spatial and temporal distribution of (PM2.5) and its relationship with the meteorological parameters.(Air temperature, Relative humidity, Precipitation and wind speed) in Iraq during two periods (2001 and 2022). The dataset adopted in the study were downloaded from the Giovanni user interface which is based on satellite remote sensing data and reanalysis by MERRA-2model which produce by NASA. The output results shows that, the seasonal and annual PM2.5 concentration values increased from 2001 to 2022 due especially in the center and south of Iraq with the highest values of PM2.5 concentration recorded in the summers of 2001 and 2022 being 172.41 micro.g/m3 and 190.06 micro.g/m3 (increased 10.24%), respectively. Because of the low average temperature and the influence of northeasterly winds bringing continental air from Central Asia, PM2.5 values in northern and northeastern Iraq are lower than those in the center and southern regions. in 2001, they ranged from 8.41 to 12.6 micro.g/m3, whereas in 2022, they ranged from 9.02 to 15.98 micro.g/m3 throughout the year. Rainfall during the cold months in the north and northeast is an essential factor in cleaning the air of PM2.5. Also, study results indicate that the max. of PM 2.5 values have consistently exceeded the upper limits of PM2.5 quarterly standards set by both the US and Iraqi regulations, for the years 2001 and 2022, but the min. PM2.5 values are within both standards.","Thu, 15 Feb 2024 19:26:46 UTC (1,531 KB)"
"28","The intermediate neutron capture process. V. The i-process in AGB stars with overshoot","A. Choplin, L. Siess, S. Goriely, S. Martinet","Solar and Stellar Astrophysics (astro-ph.SR)","The intermediate neutron capture process (i-process) can develop during proton ingestion events (PIE), potentially during the early stages of low-mass low-metallicity asymptotic giant branch (AGB) stars. We examine the impact of overshoot mixing on the triggering and development of i-process nucleosynthesis in AGB stars of various initial masses and metallicities. We computed AGB stellar models, with initial masses of 1, 2, 3, and 4 M$_{\odot}$ and metallicities in the $-2.5 \le $ [Fe/H] $\le 0$ range, using the stellar evolution code STAREVOL with a network of 1160 nuclei coupled to the transport equations. We considered different overshooting profiles below and above the thermal pulses, and below the convective envelope. The occurrence of PIEs is found to be primarily governed by the amount of overshooting at the top of pulse ($f_{\rm top}$) and to increase with rising $f_{\rm top}$. For $f_{\rm top} =$ 0, 0.02, 0.04, and 0.1, we find that 0 %, 6 %, 24 %, and 86 % of our 21 AGB models with $-2<$ [Fe/H] $<0$ experience a PIE, respectively. We also find that PIEs leave a $^{13}$C-pocket at the bottom of the pulse that can give rise to an additional radiative s-process nucleosynthesis, and ultimately produce a noticeable mixed i+s chemical signature at the surface. Finally, the chemical abundance patterns of 22 observed r/s-stars candidates with $-2<$ [Fe/H] $<-1$ are found to be in reasonable agreement with our AGB model predictions. The binary status of the dwarfs/giants being unclear, we suggest that these stars have acquired their chemical pattern either from the mass transfer of a now-extinct AGB companion or from an early generation AGB star that polluted the natal cloud. Stricter constraints from multi-dimensional hydrodynamical models on overshoot coefficients could deliver new insights into the contribution of AGB stars to heavy elements in the Universe.","Thu, 15 Feb 2024 19:24:09 UTC (3,233 KB)[v2] Wed, 21 Feb 2024 08:52:41 UTC (3,233 KB)"
"29","A Data-Driven Supervised Machine Learning Approach to Estimating Global Ambient Air Pollution Concentrations With Associated Prediction Intervals","Liam J Berrisford, Hugo Barbosa, Ronaldo Menezes","Machine Learning (cs.LG)","Global ambient air pollution, a transboundary challenge, is typically addressed through interventions relying on data from spatially sparse and heterogeneously placed monitoring stations. These stations often encounter temporal data gaps due to issues such as power outages. In response, we have developed a scalable, data-driven, supervised machine learning framework. This model is designed to impute missing temporal and spatial measurements, thereby generating a comprehensive dataset for pollutants including NO$_2$, O$_3$, PM$_{10}$, PM$_{2.5}$, and SO$_2$. The dataset, with a fine granularity of 0.25$^{\circ}$ at hourly intervals and accompanied by prediction intervals for each estimate, caters to a wide range of stakeholders relying on outdoor air pollution data for downstream assessments. This enables more detailed studies. Additionally, the model's performance across various geographical locations is examined, providing insights and recommendations for strategic placement of future monitoring stations to further enhance the model's accuracy.","Thu, 15 Feb 2024 11:09:22 UTC (38,527 KB)"
"30","Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling","Yuhui Shi, Qiang Sheng, Juan Cao, Hao Mi, Beizhe Hu, Danding Wang","Computation and Language (cs.CL)","With the rapidly increasing application of large language models (LLMs), their abuse has caused many undesirable societal problems such as fake news, academic dishonesty, and information pollution. This makes AI-generated text (AIGT) detection of great importance. Among existing methods, white-box methods are generally superior to black-box methods in terms of performance and generalizability, but they require access to LLMs' internal states and are not applicable to black-box settings. In this paper, we propose to estimate word generation probabilities as pseudo white-box features via multiple re-sampling to help improve AIGT detection under the black-box setting. Specifically, we design POGER, a proxy-guided efficient re-sampling method, which selects a small subset of representative words (e.g., 10 words) for performing multiple re-sampling in black-box AIGT detection. Experiments on datasets containing texts from humans and seven LLMs show that POGER outperforms all baselines in macro F1 under black-box, partial white-box, and out-of-distribution settings and maintains lower re-sampling costs than its existing counterparts.","Wed, 14 Feb 2024 14:32:16 UTC (494 KB)"
"31","Solid Waste Detection in Remote Sensing Images: A Survey","Piero Fraternali, Luca Morandini, Sergio Luis Herrera González","Computer Vision and Pattern Recognition (cs.CV)","The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards. Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans. Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive. Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time. Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades. Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locations for new landfills. This review aims to provide a detailed illustration of the most relevant proposals for the detection and monitoring of solid waste sites by describing and comparing the approaches, the implemented techniques, and the employed data. Furthermore, since the data sources are of the utmost importance for developing an effective solid waste detection model, a comprehensive overview of the satellites and publicly available data sets is presented. Finally, this paper identifies the open issues in the state-of-the-art and discusses the relevant research directions for reducing the costs and improving the effectiveness of novel solid waste detection methods.","Wed, 14 Feb 2024 10:24:04 UTC (491 KB)"
"32","Computational Considerations for the Linear Model of Coregionalization","Renaud Alie, David A. Stephens, Alexandra M. Schmidt","Methodology (stat.ME)","In the last two decades, the linear model of coregionalization (LMC) has been widely used to model multivariate spatial processes. From a computational standpoint, the LMC is a substantially easier model to work with than other multidimensional alternatives. Up to now, this fact has been largely overlooked in the literature. Starting from an analogy with matrix normal models, we propose a reformulation of the LMC likelihood that highlights the linear, rather than cubic, computational complexity as a function of the dimension of the response vector. Further, we describe in detail how those simplifications can be included in a Gaussian hierarchical model. In addition, we demonstrate in two examples how the disentangled version of the likelihood we derive can be exploited to improve Markov chain Monte Carlo (MCMC) based computations when conducting Bayesian inference. The first is an interwoven approach that combines samples from centered and whitened parametrizations of the latent LMC distributed random fields. The second is a sparsity-inducing method that introduces structural zeros in the coregionalization matrix in an attempt to reduce the number of parameters in a principled way. It also provides a new way to investigate the strength of the correlation among the components of the outcome vector. Both approaches come at virtually no additional cost and are shown to significantly improve MCMC performance and predictive performance respectively. We apply our methodology to a dataset comprised of air pollutant measurements in the state of California.","Wed, 14 Feb 2024 00:47:32 UTC (133 KB)"
"33","Phased Array Ultra Open Metamaterials for Broadband Acoustic Silencing","Zhiwei Yang, Ao Chen, Stephan W. Anderson, Xin Zhang","Applied Physics (physics.app-ph)","Noise pollution is a persistent environmental concern with severe implications for human health and resources. Acoustic metamaterials offer the potential for ultrathin devices with exceptional sound control capabilities. However, most lack practical openness and offer limited functional bandwidth. This paper introduces an approach utilizing a 3-unit cell phased array-based ultra-open metamaterial (3-PAUOM) to simultaneously achieve high-efficiency, broadband sound insulation combined with a high degree of ventilation. The central unit cell allows for ventilation and forms a phase gradient together with the side unit cells. The transformation of the incident plane waves into surface waves effectively blocks sound. Our design accommodates various boundary conditions and provides adjustable openness, ensuring sustained broadband sound insulation. Using length-varying straight barriers and waveguides, we theoretically, numerically, and experimentally validate our concept. This innovative approach represents a significant advancement in ventilated acoustic metamaterials, providing both ventilation and high-performance, broadband sound insulation simultaneously.","Tue, 13 Feb 2024 16:58:26 UTC (2,646 KB)"
"34","The Blocklace: A Universal, Byzantine Fault-Tolerant, Conflict-free Replicated Data Type","Paulo Sérgio Almeida, Ehud Shapiro","Distributed, Parallel, and Cluster Computing (cs.DC)","Conflict-free Replicated Data Types (CRDTs) are designed for replica convergence without global coordination or consensus. Recent work has achieves the same in a Byzantine environment, through DAG-like structures based on cryptographic hashes of content. The blocklace is a partially-ordered generalization of the blockchain in which each block has any finite number of signed hash pointers to preceding blocks. We show that the blocklace datatype, with the sole operation of adding a single block, is a CRDT: it is both a pure operation-based CRDT, with self-tagging; and a delta-state CRDT, under a slight generalization of the delta framework. Allowing arbitrary values as payload, the blocklace can also be seen as a universal Byzantine fault-tolerant implementation for arbitrary CRDTs, under the operation-based approach. Current approaches only care about CRDT convergence, being equivocation-tolerant (they do not detect or prevent equivocations), allowing a Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state with an infinite number of equivocations. We show that a blocklace can be used not only in an equivocation-tolerant way, but also so as to detect and eventually exclude Byzantine behavior, namely equivocations, even under the presence of collusion. The blocklace CRDT protocol ensures that the Byzantine nodes may harm only a finite prefix of the computation.","Mon, 12 Feb 2024 21:27:32 UTC (957 KB)[v2] Wed, 14 Feb 2024 14:32:34 UTC (957 KB)[v3] Mon, 26 Feb 2024 15:25:04 UTC (958 KB)"
"35","A Functional Coefficients Network Autoregressive Model","Hang Yin, Abolfazl Safikhani, George Michailidis","Methodology (stat.ME)","The paper introduces a flexible model for the analysis of multivariate nonlinear time series data. The proposed Functional Coefficients Network Autoregressive (FCNAR) model considers the response of each node in the network to depend in a nonlinear fashion to each own past values (autoregressive component), as well as past values of each neighbor (network component). Key issues of model stability/stationarity, together with model parameter identifiability, estimation and inference are addressed for error processes that can be heavier than Gaussian for both fixed and growing number of network nodes. The performance of the estimators for the FCNAR model is assessed on synthetic data and the applicability of the model is illustrated on multiple indicators of air pollution data.","Mon, 12 Feb 2024 02:14:49 UTC (4,219 KB)"
"36","GeoFormer: A Vision and Sequence Transformer-based Approach for Greenhouse Gas Monitoring","Madhav Khirwar, Ankur Narang","Machine Learning (cs.LG)","Air pollution represents a pivotal environmental challenge globally, playing a major role in climate change via greenhouse gas emissions and negatively affecting the health of billions. However predicting the spatial and temporal patterns of pollutants remains challenging. The scarcity of ground-based monitoring facilities and the dependency of air pollution modeling on comprehensive datasets, often inaccessible for numerous areas, complicate this issue. In this work, we introduce GeoFormer, a compact model that combines a vision transformer module with a highly efficient time-series transformer module to predict surface-level nitrogen dioxide (NO2) concentrations from Sentinel-5P satellite imagery. We train the proposed model to predict surface-level NO2 measurements using a dataset we constructed with Sentinel-5P images of ground-level monitoring stations, and their corresponding NO2 concentration readings. The proposed model attains high accuracy (MAE 5.65), demonstrating the efficacy of combining vision and time-series transformer architectures to harness satellite-derived data for enhanced GHG emission insights, proving instrumental in advancing climate change monitoring and emission regulation efforts globally.","Sun, 11 Feb 2024 11:20:29 UTC (602 KB)"
"37","Using remotely sensed data for air pollution assessment","Teresa Bernardino, Maria Alexandra Oliveira, João Nuno Silva","Machine Learning (cs.LG)","Air pollution constitutes a global problem of paramount importance that affects not only human health, but also the environment. The existence of spatial and temporal data regarding the concentrations of pollutants is crucial for performing air pollution studies and monitor emissions. However, although observation data presents great temporal coverage, the number of stations is very limited and they are usually built in more populated areas. The main objective of this work is to create models capable of inferring pollutant concentrations in locations where no observation data exists. A machine learning model, more specifically the random forest model, was developed for predicting concentrations in the Iberian Peninsula in 2019 for five selected pollutants: $NO_2$, $O_3$ $SO_2$, $PM10$, and $PM2.5$. Model features include satellite measurements, meteorological variables, land use classification, temporal variables (month, day of year), and spatial variables (latitude, longitude, altitude). The models were evaluated using various methods, including station 10-fold cross-validation, in which in each fold observations from 10\% of the stations are used as testing data and the rest as training data. The $R^2$, RMSE and mean bias were determined for each model. The $NO_2$ and $O_3$ models presented good values of $R^2$, 0.5524 and 0.7462, respectively. However, the $SO_2$, $PM10$, and $PM2.5$ models performed very poorly in this regard, with $R^2$ values of -0.0231, 0.3722, and 0.3303, respectively. All models slightly overestimated the ground concentrations, except the $O_3$ model. All models presented acceptable cross-validation RMSE, except the $O_3$ and $PM10$ models where the mean value was a little higher (12.5934 $\mu g/m^3$ and 10.4737 $\mu g/m^3$, respectively).","Sun, 4 Feb 2024 14:27:28 UTC (610 KB)"
"38","Prediction of air pollutants PM10 by ARBX(1) processes","Javier Álvarez-Liébana, M. Dolores Ruiz-Medina","Applications (stat.AP)","This work adopts a Banach-valued time series framework for component-wise estimation and prediction, from temporal correlated functional data, in presence of exogenous variables. The strong-consistency of the proposed functional estimator and associated plug-in predictor is formulated. The simulation study undertaken illustrates their large-sample size properties. Air pollutants PM10 curve forecasting, in the Haute-Normandie region (France), is addressed by implementation of the functional time series approach presented","Fri, 9 Feb 2024 17:47:42 UTC (5,594 KB)"
"39","Functional ANOVA approaches for detecting changes in air pollution during the COVID-19 pandemic","Christian Acal, Ana M. Aguilera, Annalina Sarra, Adelia Evangelista, Tonio Di Battista, Sergio Palermi","Applications (stat.AP)","Faced with novel coronavirus outbreak, the most hard-hit countries adopted a lockdown strategy to contrast the spread of virus. Many studies have already documented that the COVID-19 control actions have resulted in improved air quality locally and around the world. Following these lines of research, we focus on air quality changes in the urban territory of Chieti-Pescara (Central Italy), identified as an area of criticality in terms of air pollution. Concentrations of NO2, PM10, PM2.5 and benzene are used to evaluate air pollution changes in this Region. Data were measured by several monitoring stations over two specific periods: from 1st February to 10 th March 2020 (before lockdown period) and from 11st March 2020 to 18 th April 2020 (during lockdown period). The impact of lockdown on air quality is assessed through functional data analysis. Our work makes an important contribution to the analysis of variance for functional data (FANOVA). Specifically, a novel approach based on multivariate functional principal component analysis is introduced to tackle the multivariate FANOVA problem for independent measures, which is reduced to test multivariate homogeneity on the vectors of the most explicative principal components scores. Results of the present study suggest that the level of each pollutant changed during the confinement. Additionally, the differences in the mean functions of all pollutants according to the location and type of monitoring stations (background vs traffic), are ascribable to the PM10 and benzene concentrations for pre-lockdown and during-lockdown tenure, respectively. FANOVA has proven to be beneficial to monitoring the evolution of air quality in both periods of time. This can help environmental protection agencies in drawing a more holistic picture of air quality status in the area of interest.","Thu, 8 Feb 2024 21:29:30 UTC (2,943 KB)"
"40","The Impact of Cometary 'impacts' on the Chemistry, Climate, and Spectra of Hot Jupiter Atmospheres","Felix Sainsbury-Martinez, Catherine Walsh","Earth and Planetary Astrophysics (astro-ph.EP)","Impacts from icy and rocky bodies have helped shape the composition of solar system objects, for example the Earth-Moon system, or the recent impact of comet Shoemaker-Levy 9 with Jupiter. It is likely that such impacts also shape the composition of exoplanetary systems. Here we investigate how cometary impacts might affect the atmospheric composition/chemistry of hot Jupiters, which are prime targets for characterisation. We introduce a parametrised cometary impact model that includes thermal ablation and pressure driven breakup, which we couple with the 1D `radiative-convective' atmospheric model ATMO, including disequilibrium chemistry. We use this model to investigate a wide range of impactor masses and compositions, including those based on observations of Solar System comets, and interstellar ices (with JWST). We find that even a small impactor (R = 2.5 km) can lead to significant short-term changes in the atmospheric chemistry, including a factor $>10$ enhancement in H$_2$O, CO, CO$_2$ abundances, and atmospheric opacity more generally, and the near complete removal of observable hydrocarbons, such as CH$_4$, from the upper atmosphere. These effects scale with the change in atmospheric C/O ratio and metallicity. Potentially observable changes are possible for a body that has undergone significant/continuous bombardment, such that the global atmospheric chemistry has been impacted. Our works reveals that cometary impacts can significantly alter or pollute the atmospheric composition/chemistry of hot Jupiters. These changes have the potential to mute/break the proposed link between atmospheric C/O ratio and planet formation location relative to key snowlines in the natal protoplanetary disc.","Thu, 8 Feb 2024 09:39:42 UTC (10,150 KB)"
"41","Sustainable allocation of greenhouse gas emission permits for firms with Leontief technologies","Elisabeth Gutierrez, Natividad Llorca, Joaquin Sanchez-Soriano, Manuel A. Mosquera","Computer Science and Game Theory (cs.GT)","In this paper we deal with production situations where a cap or limit to the amount of greenhouse gas emissions permitted is imposed. Fixing a tax for each ton of pollutant emitted is also considered. We use bankruptcy rules to define cooperative games with externalities associated with these situations and analyze the existence of coalitionally stable allocations of the emission permits. We prove that the constrained equal awards ( CEA ) rule provides stable allocations and as a direct mechanism, it is incentive compatible. These two facts have interesting managerial implications to control pollution emissions.","Thu, 8 Feb 2024 09:12:11 UTC (255 KB)"
"42","cecilia: A Machine Learning-Based Pipeline for Measuring Metal Abundances of Helium-rich Polluted White Dwarfs","M. Badenas-Agusti, J. Viaña, A. Vanderburg, S. Blouin, P. Dufour, S. Xu, L. Sha","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Over the past several decades, conventional spectral analysis techniques of polluted white dwarfs have become powerful tools to learn about the geology and chemistry of extrasolar bodies. Despite their proven capabilities and extensive legacy of scientific discoveries, these techniques are however still limited by their manual, time-intensive, and iterative nature. As a result, they are susceptible to human errors and are difficult to scale up to population-wide studies of metal pollution. This paper seeks to address this problem by presenting cecilia, the first Machine Learning (ML)-powered spectral modeling code designed to measure the metal abundances of intermediate-temperature (10,000$\leq T_{\rm eff} \leq$20,000 K), Helium-rich polluted white dwarfs. Trained with more than 22,000 randomly drawn atmosphere models and stellar parameters, our pipeline aims to overcome the limitations of classical methods by replacing the generation of synthetic spectra from computationally expensive codes and uniformly spaced model grids, with a fast, automated, and efficient neural-network-based interpolator. More specifically, cecilia combines state-of-the-art atmosphere models, powerful artificial intelligence tools, and robust statistical techniques to rapidly generate synthetic spectra of polluted white dwarfs in high-dimensional space, and enable accurate ($\lesssim$0.1 dex) and simultaneous measurements of 14 stellar parameters -- including 11 elemental abundances -- from real spectroscopic observations. As massively multiplexed astronomical surveys begin scientific operations, cecilia's performance has the potential to unlock large-scale studies of extrasolar geochemistry and propel the field of white dwarf science into the era of Big Data. In doing so, we aspire to uncover new statistical insights that were previously impractical with traditional white dwarf characterisation techniques.","Wed, 7 Feb 2024 19:00:02 UTC (7,183 KB)"
"43","Quantifying Population Exposure to Long-term PM10: A City-wide Agent-based Assessment","Hyesop Shin","Multiagent Systems (cs.MA)","This study evaluates the health effects of long-term exposure to PM10 in Seoul. Building on the preliminary model Shin and Bithell (2019), an in-silico agent-based model (ABM) is used to simulate the travel patterns of individuals according to their origins and destinations. During the simulation, each person, with their inherent socio-economic attributes and allocated origin and destination location, is assumed to commute to and from the same places for 10 consecutive years. A nominal measure of their health is set to decrease whenever the concentration of PM10 exceeds the national standard. Sensitivity analysis on calibrated parameters reveals increased vulnerability among certain demographic groups, particularly those aged over 65 and under 15, with a significant health decline associated with road proximity. The study reveals a substantial health disparity after 7,000 simulation ticks (equivalent to 10 years), especially under scenarios of a 3% annual increase in pollution levels. Long-term exposure to PM10 has a significant impact on health vulnerabilities, despite initial resilience being minimal. The study emphasises the importance of future research that takes into account different pollution thresholds as well as more detailed models of population dynamics and pollution generation in order to better understand and mitigate the health effects of air pollution on diverse urban populations.","Wed, 7 Feb 2024 16:56:45 UTC (5,246 KB)"
"44","Topological relations in water quality monitoring","Bruno Chaves Figueiredo, Maria Alexandra Oliveira, João Nuno Silva","Databases (cs.DB)","The Alqueva Multi-Purpose Project (EFMA) is a massive abduction and storage infrastructure system in the Alentejo, which has a water quality monitoring network with almost thousands of water quality stations distributed across three subsystems: Alqueva, Pedrogão, and Ardila. Identification of pollution sources in complex infrastructure systems, such as the EFMA, requires recognition of water flow direction and delimitation of areas being drained to specific sampling points. The transfer channels in the EFMA infrastructure artificially connect several water bodies that do not share drainage basins, which further complicates the interpretation of water quality data because the water does not flow exclusively downstream and is not restricted to specific basins. The existing user-friendly GIS tools do not facilitate the exploration and visualisation of water quality data in spatial-temporal dimensions, such as defining temporal relationships between monitoring campaigns, nor do they allow the establishment of topological and hydrological relationships between different sampling points. This thesis work proposes a framework capable of aggregating many types of information in a GIS environment, visualising large water quality-related datasets and, a graph data model to integrate and relate water quality between monitoring stations and land use. The graph model allows to exploit the relationship between water quality in a watercourse and reservoirs associated with infrastructures. The graph data model and the developed framework demonstrated encouraging results and has proven to be preferred when compared to relational databases.","Wed, 7 Feb 2024 14:22:17 UTC (644 KB)"
"45","Controlling Moisture for Enhanced Ozone Decomposition: A Study of Water Effects on CeO$_2$ Surfaces and Catalytic Activity","Suchitra Gupta, Joon Hwan Choi, Hojin Jeong, Seung-Cheol Lee, Satadeep Bhattacharjee","Materials Science (cond-mat.mtrl-sci)","This study investigates the catalytic degradation of ground-level ozone on low-index stoichiometric and reduced CeO$_2$ surfaces using first-principles calculations. The presence of oxygen vacancies on the surface enhances the interaction between ozone and catalyst by serving as active sites for adsorption and decomposition. Our results suggest that the {111} surface has superior ozone decomposition performance due to unstable oxygen species resulting from reaction with catalysts. However, when water is present, it competes with ozone molecules for these active sites, resulting in reduced catalytic activity or water poisoning. A possible solution could be heat treatment that reduces the vacancy concentration, thereby increasing the available adsorption sites for ozone molecules while minimizing competitive adsorption by water molecules. These results suggest that controlling moisture content during operation is crucial for the efficient use of CeO$_2$-based catalysts in industrial applications to reduce ground-level ozone pollution.","Wed, 7 Feb 2024 03:43:19 UTC (6,100 KB)"
"46","Consistent Validation for Predictive Methods in Spatial Settings","David R. Burt, Yunyi Shen, Tamara Broderick","Machine Learning (stat.ML)","Spatial prediction tasks are key to weather forecasting, studying air pollution, and other scientific endeavors. Determining how much to trust predictions made by statistical or physical methods is essential for the credibility of scientific conclusions. Unfortunately, classical approaches for validation fail to handle mismatch between locations available for validation and (test) locations where we want to make predictions. This mismatch is often not an instance of covariate shift (as commonly formalized) because the validation and test locations are fixed (e.g., on a grid or at select points) rather than i.i.d. from two distributions. In the present work, we formalize a check on validation methods: that they become arbitrarily accurate as validation data becomes arbitrarily dense. We show that classical and covariate-shift methods can fail this check. We instead propose a method that builds from existing ideas in the covariate-shift literature, but adapts them to the validation data at hand. We prove that our proposal passes our check. And we demonstrate its advantages empirically on simulated and real data.","Mon, 5 Feb 2024 21:33:22 UTC (8,725 KB)"
"47","Assessing the Efficacy of Invisible Watermarks in AI-Generated Medical Images","Xiaodan Xing, Huiyu Zhou, Yingying Fang, Guang Yang","Image and Video Processing (eess.IV)","AI-generated medical images are gaining growing popularity due to their potential to address the data scarcity challenge in the real world. However, the issue of accurate identification of these synthetic images, particularly when they exhibit remarkable realism with their real copies, remains a concern. To mitigate this challenge, image generators such as DALLE and Imagen, have integrated digital watermarks aimed at facilitating the discernment of synthetic images' authenticity. These watermarks are embedded within the image pixels and are invisible to the human eye while remains their detectability. Nevertheless, a comprehensive investigation into the potential impact of these invisible watermarks on the utility of synthetic medical images has been lacking. In this study, we propose the incorporation of invisible watermarks into synthetic medical images and seek to evaluate their efficacy in the context of downstream classification tasks. Our goal is to pave the way for discussions on the viability of such watermarks in boosting the detectability of synthetic medical images, fortifying ethical standards, and safeguarding against data pollution and potential scams.","Mon, 5 Feb 2024 19:32:10 UTC (3,264 KB)[v2] Thu, 8 Feb 2024 10:30:53 UTC (3,264 KB)"
"48","Electrostatic Disturbances of Aerosol Atmospheric Plasma: Beaded Lightning","N.I. Izhovkina, S.N. Artekha, N.S. Erokhin, L.A. Mikhailovskaya","Plasma Physics (physics.plasm-ph)","Numerous sources produce the ionization impact on the planetary atmosphere. The tropospheric cloudiness therewith is originated at such altitudes, which coincide with places of the maximum of the atmospheric ionization that caused by space radiation. Components of cosmic radiation, penetrating down to the stratospheric and tropospheric altitudes, produce in the first place the ionization of aerosols that brings to subsequent amplifying the activity of atmospheric vortices. The ionized aerosol constituent is of primary importance both in the initiation of plasma vortices and in the concentration of energy-mass by air vortices due to the humidity condensation. The ionization process is cascading, that causes the non-linear impact of penetrating rays, which amplifying with growing the air pollution. Various heterogeneities inside plasma subsystems provoke the random intensification of aperiodic electrostatic disturbances, which can exert a significant action on the development of vortices. Sometimes beaded lightning arises during thunderstorm. Using the approach of the Boltzmann kinetic equation, the characteristics of electrostatic oscillations for non-uniform plasma, are analytically derived. The analytical expressions are obtained for non-magnetized plasma. In the limits of the Earth's atmosphere, these solutions are strictly applicable to the origination of electrostatic modulations along the lines of force of the geomagnetic field and approximately applicable in cases, when the impact of the Earth's magnetic field is negligible. The explicit expressions are deduced both in the hot plasma approximation and in the cold plasma approximation. It is demonstrated that the formation of chain elements of discharge in hot inhomogeneous plasma is defined by the nonmonotonic distribution of charges and fields. At such conditions, the irregularities breaks up into a cellular structure.","Mon, 5 Feb 2024 12:36:25 UTC (393 KB)"
"49","State estimation of urban air pollution with statistical, physical, and super-learning graph models","Matthieu Dolbeault, Olga Mula, Agustín Somacal","Machine Learning (cs.LG)","We consider the problem of real-time reconstruction of urban air pollution maps. The task is challenging due to the heterogeneous sources of available data, the scarcity of direct measurements, the presence of noise, and the large surfaces that need to be considered. In this work, we introduce different reconstruction methods based on posing the problem on city graphs. Our strategies can be classified as fully data-driven, physics-driven, or hybrid, and we combine them with super-learning models. The performance of the methods is tested in the case of the inner city of Paris, France.","Mon, 5 Feb 2024 08:42:39 UTC (4,722 KB)"
"50","Using Deep Ensemble Forest for High Resolution Mapping of PM2.5 from MODIS MAIAC AOD in Tehran, Iran","Hossein Bagheri","Machine Learning (cs.LG)","High resolution mapping of PM2.5 concentration over Tehran city is challenging because of the complicated behavior of numerous sources of pollution and the insufficient number of ground air quality monitoring stations. Alternatively, high resolution satellite Aerosol Optical Depth (AOD) data can be employed for high resolution mapping of PM2.5. For this purpose, different data-driven methods have been used in the literature. Recently, deep learning methods have demonstrated their ability to estimate PM2.5 from AOD data. However, these methods have several weaknesses in solving the problem of estimating PM2.5 from satellite AOD data. In this paper, the potential of the deep ensemble forest method for estimating the PM2.5 concentration from AOD data was evaluated. The results showed that the deep ensemble forest method with R2 = 0.74 gives a higher accuracy of PM2.5 estimation than deep learning methods (R2 = 0.67) as well as classic data-driven methods such as random forest (R2 = 0.68). Additionally, the estimated values of PM2.5 using the deep ensemble forest algorithm were used along with ground data to generate a high resolution map of PM2.5. Evaluation of the produced PM2.5 map revealed the good performance of the deep ensemble forest for modeling the variation of PM2.5 in the city of Tehran.","Sat, 3 Feb 2024 13:01:39 UTC (8,006 KB)"
"51","Community-based Behavioral Understanding of Crisis Activity Concerns using Social Media Data: A Study on the 2023 Canadian Wildfires in New York City","Khondhaker Al Momin, Md Sami Hasnine, Arif Mohaimin Sadri","Computers and Society (cs.CY)","New York City (NYC) topped the global chart for the worst air pollution in June 2023, owing to the wildfire smoke drifting in from Canada. This unprecedented situation caused significant travel disruptions and shifts in traditional activity patterns of NYC residents. This study utilized large-scale social media data to study different crisis activity concerns (i.e., evacuation, staying indoors, shopping, and recreational activities among others) in the emergence of the 2023 Canadian wildfire smoke in NYC. In this regard, one week (June 02 through June 09, 2023) geotagged Twitter data from NYC were retrieved and used in the analysis. The tweets were processed using advanced text classification techniques and later integrated with national databases such as Social Security Administration data, Census, and American Community Survey. Finally, a model has been developed to make community inferences of different activity concerns in a major wildfire. The findings suggest, during wildfires, females are less likely to engage in discussions about evacuation, trips for medical, social, or recreational purposes, and commuting for work, likely influenced by workplaces maintaining operations despite poor air quality. There were also racial disparities in these discussions, with Asians being more likely than Hispanics to discuss evacuation and work commute, and African Americans being less likely to discuss social and recreational activities. Additionally, individuals from low-income neighborhoods and non-higher education students expressed fewer concerns about evacuation. This study provides valuable insights for policymakers, emergency planners, and public health officials, aiding them in formulating targeted communication strategies and equitable emergency response plans.","Mon, 22 Jan 2024 06:57:45 UTC (593 KB)"
"52","Leveraging Social Media Data to Identify Factors Influencing Public Attitude Towards Accessibility, Socioeconomic Disparity and Public Transportation","Khondhaker Al Momin, Arif Mohaimin Sadri, Md Sami Hasnine","Computers and Society (cs.CY)","This study proposes a novel method to understand the factors affecting individuals' perception of transport accessibility, socioeconomic disparity, and public infrastructure. As opposed to the time consuming and expensive survey-based approach, this method can generate organic large-scale responses from social media and develop statistical models to understand individuals' perceptions of various transportation issues. This study retrieved and analyzed 36,098 tweets from New York City from March 19, 2020, to May 15, 2022. A state-of-the-art natural language processing algorithm is used for text mining and classification. A data fusion technique has been adopted to generate a series of socioeconomic traits that are used as explanatory variables in the model. The model results show that females and individuals of Asian origin tend to discuss transportation accessibility more than their counterparts, with those experiencing high neighborhood traffic also being more vocal. However, disadvantaged individuals, including the unemployed and those living in low-income neighborhoods or in areas with high natural hazard risks, tend to communicate less about such issues. As for socioeconomic disparity, individuals of Asian origin and those experiencing various types of air pollution are more likely to discuss these topics on Twitter, often with a negative sentiment. However, unemployed, or disadvantaged individuals, as well as those living in areas with high natural hazard risks or expected losses, are less inclined to tweet about this subject. Lack of internet accessibility could be a reason why many disadvantaged individuals do not tweet about transport accessibility and subsidized internet could be a possible solution.","Mon, 22 Jan 2024 06:51:29 UTC (857 KB)"
"53","Active Support of Inverters for Improving Short-Term Voltage Security in 100% IBRsPenetrated Power Systems","Yinhong Lin, Bin Wang, Qinglai Guo, Haotian Zhao, Hongbin Sun","Systems and Control (eess.SY)","Due to the energy crisis and environmental pollution, the installed capacity of inverter-based resources (IBRs) in power grids is rapidly increasing, and grid-following control (GFL) is the most prevalent at present. Meanwhile, grid-forming control-based (GFM) devices have been installed in the grid to provide active support for frequency and voltage. In the future GFL devices combined with GFM will be promising, especially in power systems with high penetration or 100% IBRs. When a short-circuit fault occurs in the grid, the controlled current source characteristic of the GFL devices leads to insufficient dynamic voltage support (DVS), while the GFM devices usually reduce the internal voltage to limit the current. Thus, deep voltage sags and undesired disconnections of IBRs may occur. Moreover, due to the dispersed locations and the control strategies' diversity of IBRs, the voltage support of different devices may not be fully coordinated, which is not conducive to short-term voltage security (STVS). To address this issue, a control scheme based on the simulation of transient characteristics of synchronous machines (SMs) is proposed. Then, a new fault ride-through strategy (FRT) is proposed based on the characteristic differences between GFL and GFM devices, and an optimization model of multi-device control parameters is formulated to meet the short-term voltage security constraints (SVSCs) and device capacity constraints. Finally, a fast solution method based on analytical modeling is proposed for the model. Test results based on the doublegenerator-one-load system, the IEEE 14-bus system, and other systems of different sizes show that the proposed method can effectively enhance the active support capability of GFL and GFM to the grid voltage, and avoid the large-scale disconnection of IBRs","Fri, 2 Feb 2024 16:09:47 UTC (1,251 KB)"
"54","Target inductive methods for zero-shot regression","Miriam Fdez-Díaz, José Ramón Quevedo, Elena Montañés","Machine Learning (cs.LG)","This research arises from the need to predict the amount of air pollutants in meteorological stations. Air pollution depends on the location of the stations (weather conditions and activities in the surroundings). Frequently, the surrounding information is not considered in the learning process. This information is known beforehand in the absence of unobserved weather conditions and remains constant for the same station. Considering the surrounding information as side information facilitates the generalization for predicting pollutants in new stations, leading to a zero-shot regression scenario. Available methods in zero-shot typically lean towards classification, and are not easily extensible to regression. This paper proposes two zero-shot methods for regression. The first method is a similarity based approach that learns models from features and aggregates them using side information. However, potential knowledge of the feature models may be lost in the aggregation. The second method overcomes this drawback by replacing the aggregation procedure and learning the correspondence between side information and feature-induced models, instead. Both proposals are compared with a baseline procedure using artificial datasets, UCI repository communities and crime datasets, and the pollutants. Both approaches outperform the baseline method, but the parameter learning approach manifests its superiority over the similarity based method.","Fri, 2 Feb 2024 09:19:45 UTC (5,665 KB)"
"55","EU-28's progress towards the 2020 renewable energy share. A club convergence analysis","María José Presno, Manuel Landajo","Econometrics (econ.EM)","This paper assesses the convergence of the EU-28 countries towards their common goal of 20% in the renewable energy share indicator by year 2020. The potential presence of clubs of convergence towards different steady state equilibria is also analyzed from both the standpoints of global convergence to the 20% goal and specific convergence to the various targets assigned to Member States. Two clubs of convergence are detected in the former case, each corresponding to different RES targets. A probit model is also fitted with the aim of better understanding the determinants of club membership, that seemingly include real GDP per capita, expenditure on environmental protection, energy dependence, and nuclear capacity, with all of them having statistically significant effects. Finally, convergence is also analyzed separately for the transport, heating and cooling, and electricity sectors.","Thu, 1 Feb 2024 17:21:52 UTC (753 KB)"
"56","Determination of Trace Organic Contaminant Concentration via Machine Classification of Surface-Enhanced Raman Spectra","Vishnu Jayaprakash, Jae Bem You, Chiranjeevi Kanike, Jinfeng Liu, Christopher McCallum, Xuehua Zhang","Machine Learning (cs.LG)","Accurate detection and analysis of traces of persistent organic pollutants in water is important in many areas, including environmental monitoring and food quality control, due to their long environmental stability and potential bioaccumulation. While conventional analysis of organic pollutants requires expensive equipment, surface enhanced Raman spectroscopy (SERS) has demonstrated great potential for accurate detection of these contaminants. However, SERS analytical difficulties, such as spectral preprocessing, denoising, and substrate-based spectral variation, have hindered widespread use of the technique. Here, we demonstrate an approach for predicting the concentration of sample pollutants from messy, unprocessed Raman data using machine learning. Frequency domain transform methods, including the Fourier and Walsh Hadamard transforms, are applied to sets of Raman spectra of three model micropollutants in water (rhodamine 6G, chlorpyrifos, and triclosan), which are then used to train machine learning algorithms. Using standard machine learning models, the concentration of sample pollutants are predicted with more than 80 percent cross-validation accuracy from raw Raman data. cross-validation accuracy of 85 percent was achieved using deep learning for a moderately sized dataset (100 spectra), and 70 to 80 percent cross-validation accuracy was achieved even for very small datasets (50 spectra). Additionally, standard models were shown to accurately identify characteristic peaks via analysis of their importance scores. The approach shown here has the potential to be applied to facilitate accurate detection and analysis of persistent organic pollutants by surface-enhanced Raman spectroscopy.","Wed, 31 Jan 2024 21:49:40 UTC (3,403 KB)"
"57","Development of biochar molecular models with controlled porosity","Audrey Ngambia, Ondřej Mašek, Valentina Erastova","Materials Science (cond-mat.mtrl-sci)","Biochars are an exciting class of environmental materials with a wide range of applications, including carbon storage and sequestration, soil enhancement, and pollution remediation. However, the limited knowledge of their molecular structures and compositions and the lack of comprehensive understanding of the relationship between these structures and biochars' diverse functionality, is hindering advancements in their development. In this work, we further advance the approach, first introduced by Wood et al. (2023), to constructing biochar molecular models; and now include control of microporosity (pores < 2 nm size) within the developed models. We construct biochar models representative of woody biochars which are experimentally produced at 600 -- 650 oC highest heating temperatures. Our models reproduce experimental H/C and O/C atomic ratios, percentage aromatic carbon, true density, cumulative porosity, and pore size distribution. The development of microporous biochar molecular models allows us to identify the importance of chemical structures involved in the assembly of biochar materials, and describe the relationship between these structures and obtained micropores. To facilitate other researchers integrating our approach into their work, we detail the steps taken, including the tests and reasons for each decision, in the construction of the biochar models. Furthermore, we share our developed molecular models in a format that can be easily integrated into other group's work in the form of molecular dynamics simulations.","Tue, 30 Jan 2024 20:10:02 UTC (28,770 KB)"
"58","Causal Analysis of Air Pollution Mixtures: Estimands, Positivity, and Extrapolation","Joseph Antonelli, Corwin Zigler","Methodology (stat.ME)","Causal inference for air pollution mixtures is an increasingly important issue with appreciable challenges. When the exposure is a multivariate mixture, there are many exposure contrasts that may be of nominal interest for causal effect estimation, but the complex joint mixture distribution often renders observed data extremely limited in their ability to inform estimates of many commonly-defined causal effects. We use potential outcomes to 1) define causal effects of air pollution mixtures, 2) formalize the key assumption of mixture positivity required for estimation and 3) offer diagnostic metrics for positivity violations in the mixture setting that allow researchers to assess the extent to which data can actually support estimation of mixture effects of interest. For settings where there is limited empirical support, we redefine causal estimands that apportion causal effects according to whether they can be directly informed by observed data versus rely entirely on model extrapolation, isolating key sources of information on the causal effect of an air pollution mixture. The ideas are deployed to assess the ability of a national United States data set on the chemical components of ambient particulate matter air pollution to support estimation of a variety of causal mixture effects.","Tue, 30 Jan 2024 19:10:37 UTC (114 KB)"
"59","Assessing Public Perception of Car Automation in Iran: Acceptance and Willingness to Pay for Adaptive Cruise Control","Sina Sahebi, Sahand Heshami, Mohammad Khojastehpour, Ali Rahimi, Mahyar Mollajani","General Economics (econ.GN)","Adaptive cruise control (ACC) is a technology that can reduce fuel consumption and air pollution in the automotive industry. However, its availability in Iran is low compared to industrialized countries. This study examines the acceptance and willingness to pay (WTP) for ACC among Iranian drivers. Data from an online survey of 453 respondents were analyzed using the Technology Acceptance Model (TAM) and an ordered logit model. The results show that perceived ease of use and perceived usefulness affect attitudes toward using ACC, which in turn influence behavioral intentions. The logit model also shows that drivers who find ACC easy and useful, who have higher vehicle prices, and who are women with cruise control (CC) experience are more likely to pay for ACC. To increase the adoption of ACC in Iran, it is suggested to target early adopters, especially women and capitalists, who can influence others with their positive feedback. The benefits of ACC for traffic safety and environmental sustainability should also be emphasized.","Mon, 29 Jan 2024 19:28:42 UTC (555 KB)"
"60","Variation in Patterns of Metal Accumulation in Thallus Parts of Lessonia trabeculata (Laminariales; Phaeophyceae): Implications for Biomonitoring","C. A. Saez, M. G. Lobos, E. C. Macaya, D. Oliva, W. Quiroz, M. T. Brown","Other Quantitative Biology (q-bio.OT)","Seaweeds are well known to concentrate metals from seawater and have been employed as monitors of metal pollution in coastal waters and estuaries. However, research showing that various intrinsic and extrinsic factors can influence metal accumulation, raises doubts about the basis for using seaweeds in biomonitoring programmes. The thallus of brown seaweeds of the order Laminariales (kelps) is morphologically complex but there is limited information about the variation in metal accumulation between the different parts, which might result in erroneous conclusions being drawn if not accounted for in the biomonitoring protocol. To assess patterns of individual metals in the differentiated parts of the thallus (blade, stipe, holdfast), concentrations of a wide range of essential and non-essential metals (Fe, Cr, Cu, Zn, Mn, Pb, Cd, Ni and Al) were measured in the kelp Lessonia trabeculata. Seaweeds were collected from three sampling stations located at 5, 30 and 60 m from an illegal sewage outfall close to Ventanas, Chile and from a pristine location at Faro Curaumilla. For the majority of metals the highest concentrations in bottom sediment and seaweed samples were found at the site closest to the outfall, with concentrations decreasing with distance from the outfall and at control stations; the exception was Cd, concentrations of which were higher at control stations. The patterns of metal concentrations in different thallus parts were metal specific and independent of sampling station. These results and the available literature suggest that biomonitoring of metals using seaweeds must take account of differences in the accumulation of metals in thallus parts of complex seaweeds","Wed, 24 Jan 2024 16:52:57 UTC (1,275 KB)"
"61","Multi-modal Representation Learning for Cross-modal Prediction of Continuous Weather Patterns from Discrete Low-Dimensional Data","Alif Bin Abdul Qayyum, Xihaier Luo, Nathan M. Urban, Xiaoning Qian, Byung-Jun Yoon","Machine Learning (cs.LG)","World is looking for clean and renewable energy sources that do not pollute the environment, in an attempt to reduce greenhouse gas emissions that contribute to global warming. Wind energy has significant potential to not only reduce greenhouse emission, but also meet the ever increasing demand for energy. To enable the effective utilization of wind energy, addressing the following three challenges in wind data analysis is crucial. Firstly, improving data resolution in various climate conditions to ensure an ample supply of information for assessing potential energy resources. Secondly, implementing dimensionality reduction techniques for data collected from sensors/simulations to efficiently manage and store large datasets. Thirdly, extrapolating wind data from one spatial specification to another, particularly in cases where data acquisition may be impractical or costly. We propose a deep learning based approach to achieve multi-modal continuous resolution wind data prediction from discontinuous wind data, along with data dimensionality reduction.","Tue, 30 Jan 2024 12:03:40 UTC (8,839 KB)"
"62","Application of Methods of Artificial Intelligence in Systems for Continuous Automatic Monitoring of Dust Concentration and Deposits in Mine Atmosphere","Daria Trubicina, Kirill Varnavskiy, Alexander Ermakov, Fedor Nepsha, Roman Kozlov, Naser Golsanami, Sergey Zhironkin","Systems and Control (eess.SY)","With the growth of coal production, the load on the production capacity of coal enterprises also increases, which leads to a concomitant increase in dust formation in both opencast and underground methods of mining coal deposits. Dust, generated during drilling, blasting operations, excavation, loading, crushing and transportation of mined rock is one of the factors that has a negative impact on the health of mining workers and on the level of environmental pollution with solid particles. Thus, increasing the efficiency of controlling the concentration of solid particles in the mine atmosphere and dust deposits is an urgent scientific and technical task. In doing so, the use of modern digital technologies within the framework of the industry 4.0 concept makes it possible to develop approaches that can significantly improve the quality of monitoring the state of the mine atmosphere at coal mining enterprises. This article provides a theoretical basis and test results for a system for continuous automatic monitoring of dust concentration in a mine atmosphere as the component of the multifunctional coal mine safety system. It is shown that monitoring the state of mine workings aerological safety can be carried out in real time through the system of the new generation using artificial intelligence. The ability of the proposed system to measure basic physical parameters affecting dust deposition (disperse composition, air humidity, dust concentration and air flow velocity) is noted.","Tue, 30 Jan 2024 09:02:11 UTC (374 KB)"
"63","The Carbon Premium: Correlation or Causation? Evidence from S&P 500 Companies","Namasi G. Sankar, Suryadeepto Nag, Siddhartha P. Chakrabarty, Sankarshan Basu","Pricing of Securities (q-fin.PR)","In the context of whether investors are aware of carbon-related risks, it is often hypothesized that there may be a carbon premium in the value of stocks of firms, conferring an abnormal excess value to firms' shares as a form of compensation to investors for their transition risk exposure through the ownership of carbon instensive stocks. However, there is little consensus in the literature regarding the existence of such a premium. Moreover few studies have examined whether the correlation that is often observed is actually causal. The pertinent question is whether more polluting firms give higher returns or do firms with high returns have less incentive to decarbonize? In this study, we investigate whether firms' emissions is causally linked to the presence of a carbon premium in a panel of 141 firms listed in the S\&P500 index using fixed-effects analysis, with propensity score weighting to control for selection bias in which firms increase their emissions. We find that there is a statistically significant positive carbon premium associated with Scope 1 emissions, while there is no significant premium associated with Scope 2 emissions, implying that risks associated with direct emissions by the firm are priced, while bought emissions are not.","Mon, 29 Jan 2024 08:32:10 UTC (245 KB)"
"64","The geometric error is less than the pollution error when solving the high-frequency Helmholtz equation with high-order FEM on curved domains","Théophile Chaumont-Frelet, Euan A. Spence","Numerical Analysis (math.NA)","We consider the $h$-version of the finite-element method, where accuracy is increased by decreasing the meshwidth $h$ while keeping the polynomial degree $p$ constant, applied to the Helmholtz equation. Although the question ""how quickly must $h$ decrease as the wavenumber $k$ increases to maintain accuracy?"" has been studied intensively since the 1990s, none of the existing rigorous wavenumber-explicit analyses take into account the approximation of the geometry. In this paper we prove that for nontrapping problems solved using straight elements the geometric error is order $kh$, which is then less than the pollution error $k(kh)^{2p}$ when $k$ is large; this fact is then illustrated in numerical experiments. More generally, we prove that, even for problems with strong trapping, using degree four (in 2-d) or degree five (in 3-d) polynomials and isoparametric elements ensures that the geometric error is smaller than the pollution error for most large wavenumbers.","Mon, 29 Jan 2024 18:50:24 UTC (32 KB)"
"65","SAT-CEP-monitor: An air quality monitoring software architecture combining complex event processing with satellite remote sensing","Badr-Eddine Boudriki Semlali, Chaker El Amrani, Guadalupe Ortiz, Juan Boubeta-Puig, Alfonso Garcia-de-Prado","Distributed, Parallel, and Cluster Computing (cs.DC)","Air pollution is a major problem today that causes serious damage to human health. Urban areas are the most affected by the degradation of air quality caused by anthropogenic gas emissions. Although there are multiple proposals for air quality monitoring, in most cases, two limitations are imposed: the impossibility of processing data in Near Real-Time (NRT) for remote sensing approaches and the impossibility of reaching areas of limited accessibility or low network coverage for ground data approaches. We propose a software architecture that efficiently combines complex event processing with remote sensing data from various satellite sensors to monitor air quality in NRT, giving support to decision-makers. We illustrate the proposed solution by calculating the air quality levels for several areas of Morocco and Spain, extracting and processing satellite information in NRT. This study also validates the air quality measured by ground stations and satellite sensor data.","Mon, 29 Jan 2024 17:45:23 UTC (6,404 KB)"
"66","Detection of metal enrichment by SN 2011jm in NGC 4809","Yulong Gao, Qiusheng Gu, Ping Zhou, Shi Yong, Xiangdong Li","Astrophysics of Galaxies (astro-ph.GA)","The cosmic metals are believed to originate from stellar and supernovae (SNe) nucleosynthesis, dispersed into the interstellar medium (ISM) through stellar winds and supernova explosions. In this paper, we present the clear evidence of metal enrichment by a type Ic SN 2011jm in the galaxy NGC 4809, utilizing high spatial resolution Integral Field Units (IFU) observations obtained from the Very Large Telescope (VLT)/Multi Unit Spectroscopic Explorer (MUSE). Despite SN 2011jm being surrounded by metal-deficient ISM ($\sim 0.25 \ Z_\odot$) at a scale about 100 pc, we clearly detect enriched oxygen abundance ($\sim 0.35 \ Z_\odot$) and a noteworthy nitrogen-to-oxygen ratio at the SN site. Remarkably, the metal pollution is confined to a smaller scale ( $\leq$ 13 pc). We posit that the enhanced ionized metal stems from stellar winds emitted by massive stars or previous SNe explosions. This observation may represent the first direct detection of chemical pollution by stellar feedback in star-forming galaxies beyond the Local Volume.","Mon, 29 Jan 2024 14:05:17 UTC (282 KB)"
"67","Does green innovation crowd out other innovation of firms? Based on the extended CDM model and unconditional quantile regressions","Yi Jiang, Richard S.J. Tol","General Economics (econ.GN)","In the era of sustainability, firms grapple with the decision of how much to invest in green innovation and how it influences their economic trajectory. This study employs the Crepon, Duguet, and Mairesse (CDM) framework to examine the conversion of R&D funds into patents and their impact on productivity, effectively addressing endogeneity by utilizing predicted dependent variables at each stage to exclude unobservable factors. Extending the classical CDM model, this study contrasts green and non-green innovations' economic effects. The results show non-green patents predominantly drive productivity gains, while green patents have a limited impact in non-heavy polluting firms. However, in high-pollution and manufacturing sectors, both innovation types equally enhance productivity. Using unconditional quantile regression, I found green innovation's productivity impact follows an inverse U-shape, unlike the U-shaped pattern of non-green innovation. Significantly, in the 50th to 80th productivity percentiles of manufacturing and high-pollution firms, green innovation not only contributes to environmental sustainability but also outperforms non-green innovation economically.","Mon, 29 Jan 2024 10:29:13 UTC (2,957 KB)[v2] Sun, 4 Feb 2024 21:17:32 UTC (2,957 KB)"
"68","A Scalable Approach to Equitable Facility Location","Drew Horton, Tom Logan, Joshua Murrell, Daphne Skipper, Emily Speakman","Optimization and Control (math.OC)","In the environmental justice literature, the Kolm-Pollak Equally Distributed Equivalent (EDE) is the preferred metric for comparing distributions of negative environmental factors, such as pollution or distance to an essential service. The Kolm-Pollak EDE penalizes for inequality at a level prescribed by an aversion to inequality parameter, thereby, capturing the experience of an average individual more accurately than the population mean. We explore the problem of optimizing the Kolm-Pollak EDE both with and without a penalty term in the objective function. Optimizing over the nonlinear Kolm-Pollak EDE directly in a facility location model, which requires integer variables, is not scalable. However, we present an integer linear facility location model that optimizes the Kolm-Pollak EDE exactly, modulo parameter estimation. Computational tests demonstrate that the linear model has a similar computational burden as optimizing over the population mean, so our model scales to very large practical problem instances. Moreover, distributions of distances corresponding to optimal solutions to our model, in comparison with solutions obtained from optimizing the mean, significantly improve the situations of the worst-off residents (with respect to distance from an open amenity), while also attaining a near-optimal mean.","Sat, 27 Jan 2024 16:25:57 UTC (552 KB)"
"69","pLitterStreet: Street Level Plastic Litter Detection and Mapping","Sriram Reddy Mandhati, N. Lakmal Deshapriya, Chatura Lavanga Mendis, Kavinda Gunasekara, Frank Yrle, Angsana Chaksan, Sujit Sanjeev","Computer Vision and Pattern Recognition (cs.CV)","Plastic pollution is a critical environmental issue, and detecting and monitoring plastic litter is crucial to mitigate its impact. This paper presents the methodology of mapping street-level litter, focusing primarily on plastic waste and the location of trash bins. Our methodology involves employing a deep learning technique to identify litter and trash bins from street-level imagery taken by a camera mounted on a vehicle. Subsequently, we utilized heat maps to visually represent the distribution of litter and trash bins throughout cities. Additionally, we provide details about the creation of an open-source dataset (""pLitterStreet"") which was developed and utilized in our approach. The dataset contains more than 13,000 fully annotated images collected from vehicle-mounted cameras and includes bounding box labels. To evaluate the effectiveness of our dataset, we tested four well known state-of-the-art object detection algorithms (Faster R-CNN, RetinaNet, YOLOv3, and YOLOv5), achieving an average precision (AP) above 40%. While the results show average metrics, our experiments demonstrated the reliability of using vehicle-mounted cameras for plastic litter mapping. The ""pLitterStreet"" can also be a valuable resource for researchers and practitioners to develop and further improve existing machine learning models for detecting and mapping plastic litter in an urban environment. The dataset is open-source and more details about the dataset and trained models can be found at this https URL.","Fri, 26 Jan 2024 08:59:48 UTC (867 KB)"
"70","Case-crossover designs and overdispersion with application in air pollution epidemiology","Samuel Perreault, Gracia Y. Dong, Alex Stringer, Hwashin Shin, Patrick Brown","Methodology (stat.ME)","Over the last three decades, case-crossover designs have found many applications in health sciences, especially in air pollution epidemiology. They are typically used, in combination with partial likelihood techniques, to define a conditional logistic model for the responses, usually health outcomes, conditional on the exposures. Despite the fact that conditional logistic models have been shown equivalent, in typical air pollution epidemiology setups, to specific instances of the well-known Poisson time series model, it is often claimed that they cannot allow for overdispersion. This paper clarifies the relationship between case-crossover designs, the models that ensue from their use, and overdispersion. In particular, we propose to relax the assumption of independence between individuals traditionally made in case-crossover analyses, in order to explicitly introduce overdispersion in the conditional logistic model. As we show, the resulting overdispersed conditional logistic model coincides with the overdispersed, conditional Poisson model, in the sense that their likelihoods are simple re-expressions of one another. We further provide the technical details of a Bayesian implementation of the proposed case-crossover model, which we use to demonstrate, by means of a large simulation study, that standard case-crossover models can lead to dramatically underestimated coverage probabilities, while the proposed models do not. We also perform an illustrative analysis of the association between air pollution and morbidity in Toronto, Canada, which shows that the proposed models are more robust than standard ones to outliers such as those associated with public holidays.","Thu, 25 Jan 2024 17:37:29 UTC (27,341 KB)"
"71","JWST Directly Images Giant Planet Candidates Around Two Metal-Polluted White Dwarf Stars","Susan E. Mullally, John Debes, Misty Cracraft, Fergal Mullally, Sabrina Poulsen, Loic Albert, Katherine Thibault, William T. Reach, J. J. Hermes, Thomas Barclay, Mukremin Kilic, Elisa V. Quintana","Earth and Planetary Astrophysics (astro-ph.EP)","We report the discovery of two directly imaged, giant planet candidates orbiting the metal-rich DAZ white dwarfs WD 1202-232 and WD 2105-82. JWST's Mid-Infrared Instrument (MIRI) data on these two stars show a nearby resolved source at a projected separation of 11.47 and 34.62 au, respectively. Assuming the planets formed at the same time as their host stars, with total ages of 5.3 and 1.6Gyr, the MIRI photometry is consistent with giant planets with masses about 1-7 Jupiter Masses. The probability of both candidates being false positives due to red background sources is approximately 1 in 3000. If confirmed, these would be the first directly imaged planets that are similar in both age and separation to the giant planets in our own solar system, and they would demonstrate that widely separated giant planets like Jupiter survive stellar evolution. Giant planet perturbers are widely used to explain the tidal disruption of asteroids around metal-polluted white dwarfs. Confirmation of these two planet candidates with future MIRI imaging would provide evidence that directly links giant planets to metal pollution in white dwarf stars.","Wed, 24 Jan 2024 00:00:27 UTC (419 KB)"
"72","Towards a prioritised use of transportation infrastructures: the case of vehicle-specific dynamic access restrictions to city centres","Holger Billhardt, Alberto Fernández, Pasqual Martí, Javier Prieto Tejedor, Sascha Ossowski","Physics and Society (physics.soc-ph)","One of the main problems that local authorities of large cities have to face is the regulation of urban mobility. They need to provide the means to allow for the efficient movement of people and distribution of goods. However, the provisioning of transportation services needs to take into account general global objectives, like reducing emissions and having more healthy living environments, which may not always be aligned with individual interests. Urban mobility is usually provided through a transport infrastructure that includes all the elements that support mobility. On many occasions, the capacity of the elements of this infrastructure is lower than the actual demand and thus different transportation activities compete for their use. In this paper, we argue that scarce transport infrastructure elements should be assigned dynamically and in a prioritised manner to transport activities that have a higher utility from the point of view of society; for example, activities that produce less pollution and provide more value to society. In this paper, we define a general model for prioritizing the use of a particular type of transportation infrastructure element called time-unlimited elements, whose usage time is unknown a priori, and illustrate its dynamics through two use cases: vehicle-specific dynamic access restriction in city centres (i) based on the usage levels of available parking spaces and (ii) to assure sustained admissible air quality levels in the city centre. We carry out several experiments using the SUMO traffic simulation tool to evaluate our proposal.","Mon, 22 Jan 2024 19:43:54 UTC (482 KB)"
"73","Spatial-temporal Forecasting for Regions without Observations","Xinyu Su, Jianzhong Qi, Egemen Tanin, Yanchuan Chang, Majid Sarvi","Machine Learning (cs.LG)","Spatial-temporal forecasting plays an important role in many real-world applications, such as traffic forecasting, air pollutant forecasting, crowd-flow forecasting, and so on. State-of-the-art spatial-temporal forecasting models take data-driven approaches and rely heavily on data availability. Such models suffer from accuracy issues when data is incomplete, which is common in reality due to the heavy costs of deploying and maintaining sensors for data collection. A few recent studies attempted to address the issue of incomplete data. They typically assume some data availability in a region of interest either for a short period or at a few locations. In this paper, we further study spatial-temporal forecasting for a region of interest without any historical observations, to address scenarios such as unbalanced region development, progressive deployment of sensors or lack of open data. We propose a model named STSM for the task. The model takes a contrastive learning-based approach to learn spatial-temporal patterns from adjacent regions that have recorded data. Our key insight is to learn from the locations that resemble those in the region of interest, and we propose a selective masking strategy to enable the learning. As a result, our model outperforms adapted state-of-the-art models, reducing errors consistently over both traffic and air pollutant forecasting tasks. The source code is available at this https URL.","Fri, 19 Jan 2024 06:26:05 UTC (6,641 KB)"
"74","Building a Life Cycle Assessment Model using Bayesian Networks","Cedric Fraces Gasmi, Wennan Long","Data Analysis, Statistics and Probability (physics.data-an)","This paper introduces the Oilfield Pollutant Graphical Model (OPGM), an innovative approach designed to improve the benchmarking and uncertainty analysis of greenhouse gas (GHG) emissions in oilfields. Building on the robust foundation provided by the Oil Production Greenhouse Gas Emission Estimator (OPGEE) framework, OPGM retains all essential functionalities of the latest OPGEE iteration (v3.0c), while offering substantial improvements in user experience and computational performance. Key advances of OPGM include a streamlined user interface for more intuitive interaction, which facilitates transparent visualization of intermediate results and thus contributes to a more interpretable and accessible analysis process. A notable feature of the OPGM is its ability to naturally perform sensitivity analyzes. This is achieved by allowing users to seamlessly transition nodes from deterministic to probabilistic, thereby integrating uncertainty directly into the core structure of the model. OPGM achieves remarkable computational efficiency, executing analyzes at a speed 1e+5 times faster than the Excel-based OPGEE, thus facilitating rapid large-scale emissions assessments. This leap in processing speed represents a significant step forward in emissions modeling, enabling more agile and accurate environmental impact assessments. The integration of OPGM into existing Life Cycle Assessment (LCA) practices holds the promise of significantly improving the precision and speed of environmental impact analyses, offering a vital tool for policymakers and industry stakeholders in their efforts to better understand and manage the environmental impacts of oilfield operations.","Thu, 11 Jan 2024 22:13:00 UTC (17,062 KB)"
"75","A Framework for Scalable Ambient Air Pollution Concentration Estimation","Liam J Berrisford, Lucy S Neal, Helen J Buttery, Benjamin R Evans, Ronaldo Menezes","Applications (stat.AP)","Ambient air pollution remains a critical issue in the United Kingdom, where data on air pollution concentrations form the foundation for interventions aimed at improving air quality. However, the current air pollution monitoring station network in the UK is characterized by spatial sparsity, heterogeneous placement, and frequent temporal data gaps, often due to issues such as power outages. We introduce a scalable data-driven supervised machine learning model framework designed to address temporal and spatial data gaps by filling missing measurements. This approach provides a comprehensive dataset for England throughout 2018 at a 1kmx1km hourly resolution. Leveraging machine learning techniques and real-world data from the sparsely distributed monitoring stations, we generate 355,827 synthetic monitoring stations across the study area, yielding data valued at approximately \pounds70 billion. Validation was conducted to assess the model's performance in forecasting, estimating missing locations, and capturing peak concentrations. The resulting dataset is of particular interest to a diverse range of stakeholders engaged in downstream assessments supported by outdoor air pollution concentration data for NO2, O3, PM10, PM2.5, and SO2. This resource empowers stakeholders to conduct studies at a higher resolution than was previously possible.","Tue, 16 Jan 2024 18:03:07 UTC (19,962 KB)"
"76","Contrastive Learning with Negative Sampling Correction","Lu Wang, Chao Du, Pu Zhao, Chuan Luo, Zhangchi Zhu, Bo Qiao, Wei Zhang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang","Machine Learning (cs.LG)","As one of the most effective self-supervised representation learning methods, contrastive learning (CL) relies on multiple negative pairs to contrast against each positive pair. In the standard practice of contrastive learning, data augmentation methods are utilized to generate both positive and negative pairs. While existing works have been focusing on improving the positive sampling, the negative sampling process is often overlooked. In fact, the generated negative samples are often polluted by positive samples, which leads to a biased loss and performance degradation. To correct the negative sampling bias, we propose a novel contrastive learning method named Positive-Unlabeled Contrastive Learning (PUCL). PUCL treats the generated negative samples as unlabeled samples and uses information from positive samples to correct bias in contrastive loss. We prove that the corrected loss used in PUCL only incurs a negligible bias compared to the unbiased contrastive loss. PUCL can be applied to general contrastive learning problems and outperforms state-of-the-art methods on various image and graph classification tasks. The code of PUCL is in the supplementary file.","Sat, 13 Jan 2024 11:18:18 UTC (7,599 KB)"
"77","BOATS: Bayesian Optimization for Active Control of ThermoacousticS","Bayu Dharmaputra, Pit Reckinger, Bruno Schuermans, Nicolas Noiray","Optimization and Control (math.OC)","This investigation presents novel adaptive control algorithms specifically designed to address and mitigate thermoacoustic instabilities. Two control strategies are available to alleviate this issue: active and passive. Active control strategies have a wider flexibility than passive control strategies because they can adapt to the operating conditions of the gas turbine. However, optimizing the control parameters remains a challenge, especially if additional constraints have to be fulfilled, such as e.g. pollutant emission levels. To address this issue, we propose three adaptive control strategies based on Bayesian optimization. The first and foundational algorithm is the safeOpt algorithm, and the two adaptations that have been made are stageOpt and shrinkAlgo. The Gaussian Process Regressor (GPR) is employed to approximate both the objective and constraint functions, with continuous updates occurring during iterations. The algorithms also enable the transfer of knowledge obtained from one operating point to another, thereby reducing the number of iterations needed to reach the optimal point. We demonstrate the effectiveness of the algorithms both numerically and through two distinct experimental validations. In the numerical demonstration, we employ a low-order thermoacoustic network model to simulate a single-stage combustor setup equipped with loudspeaker actuation and a gain-delay ($n-\tau$) controller for active stabilization. The first experimental demonstration has the same structure as the numerical case. For the second experimental validation, we apply the framework to a sequential combustor configuration utilizing nanosecond repetitively pulsed discharges (NRPD) as the control actuator. This demonstrates the framework's adaptability to various control actuation methods in turbulent combustors where control parameter optimization is required.","Mon, 15 Jan 2024 17:57:24 UTC (6,993 KB)"
"78","Graphical Principal Component Analysis of Multivariate Functional Time Series","Jianbin Tan, Decai Liang, Yongtao Guan, Hui Huang","Methodology (stat.ME)","In this paper, we consider multivariate functional time series with a two-way dependence structure: a serial dependence across time points and a graphical interaction among the multiple functions within each time point. We develop the notion of dynamic weak separability, a more general condition than those assumed in literature, and use it to characterize the two-way structure in multivariate functional time series. Based on the proposed weak separability, we develop a unified framework for functional graphical models and dynamic principal component analysis, and further extend it to optimally reconstruct signals from contaminated functional data using graphical-level information. We investigate asymptotic properties of the resulting estimators and illustrate the effectiveness of our proposed approach through extensive simulations. We apply our method to hourly air pollution data that were collected from a monitoring network in China.","Sat, 13 Jan 2024 06:22:07 UTC (468 KB)"
"79","Causally Aware Generative Adversarial Networks for Light Pollution Control","Yuyao Zhang, Ke Guo, Xiao Zhou","Computers and Society (cs.CY)","Artificial light plays an integral role in modern cities, significantly enhancing human productivity and the efficiency of civilization. However, excessive illumination can lead to light pollution, posing non-negligible threats to economic burdens, ecosystems, and human health. Despite its critical importance, the exploration of its causes remains relatively limited within the field of artificial intelligence, leaving an incomplete understanding of the factors contributing to light pollution and sustainable illumination planning distant. To address this gap, we introduce a novel framework named Causally Aware Generative Adversarial Networks (CAGAN). This innovative approach aims to uncover the fundamental drivers of light pollution within cities and offer intelligent solutions for optimal illumination resource allocation in the context of sustainable urban development. We commence by examining light pollution across 33,593 residential areas in seven global metropolises. Our findings reveal substantial influences on light pollution levels from various building types, notably grasslands, commercial centers and residential buildings as significant contributors. These discovered causal relationships are seamlessly integrated into the generative modeling framework, guiding the process of generating light pollution maps for diverse residential areas. Extensive experiments showcase CAGAN's potential to inform and guide the implementation of effective strategies to mitigate light pollution. Our code and data are publicly available at this https URL.","Fri, 12 Jan 2024 08:57:20 UTC (3,890 KB)"
"80","UDEEP: Edge-based Computer Vision for In-Situ Underwater Crayfish and Plastic Detection","Dennis Monari, Jack Larkin, Pedro Machado, Jordan J. Bird, Isibor Kennedy Ihianle, Salisu Wada Yahaya, Farhad Fassihi Tash, Md Mahmudul Hasan, Ahmad Lotfi","Computer Vision and Pattern Recognition (cs.CV)","Invasive signal crayfish have a detrimental impact on ecosystems. They spread the fungal-type crayfish plague disease (Aphanomyces astaci) that is lethal to the native white clawed crayfish, the only native crayfish species in Britain. Invasive signal crayfish extensively burrow, causing habitat destruction, erosion of river banks and adverse changes in water quality, while also competing with native species for resources and leading to declines in native populations. Moreover, pollution exacerbates the vulnerability of White-clawed crayfish, with their populations declining by over 90% in certain English counties, making them highly susceptible to extinction. To safeguard aquatic ecosystems, it is imperative to address the challenges posed by invasive species and discarded plastics in the United Kingdom's river ecosystem's. The UDEEP platform can play a crucial role in environmental monitoring by performing on-the-fly classification of Signal crayfish and plastic debris while leveraging the efficacy of AI, IoT devices and the power of edge computing (i.e., NJN). By providing accurate data on the presence, spread and abundance of these species, the UDEEP platform can contribute to monitoring efforts and aid in mitigating the spread of invasive species.","Thu, 21 Dec 2023 16:03:59 UTC (9,466 KB)"
"81","On the fast computation of the observer motion effects induced on monopole frequency spectra for tabulated functions","Tiziana Trombetti, Carlo Burigana, Marco Tucci, Luigi Toffolatti","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Methods are studied to compute the boosting effects produced by the observer motion that modifies and transfers to higher l the isotropic monopole frequency spectrum of the cosmic background. Explicit analytical solutions for spherical harmonic coefficients are presented and applied to various background spectra, alleviating computational effort. High l frequency spectra are led by higher order derivatives of the spectrum. Tabulated frequency spectra are computed with a relatively poor frequency resolution in comparison with the Doppler shift, calling for interpolation. They are affected by uncertainties due to intrinsic inaccuracies in modelling, observational data or limited computation accuracy, propagate and increase with the derivative order, possibly preventing a trustworthy computation to higher l and of the observed monopole. We filter the original function and the multipole spectra to derive reliable predictions of the harmonic coefficients. For spectra expressed in Taylor series, we derive explicit solutions for the harmonic coefficients up to l=6 in terms of spectra derivatives. We consider filters and study the quality of these methods on suitable analytical approximations, polluted with simulated noise. We consider the extragalactic sources microwave background from radio loud AGN and the 21cm line superimposed to the CMB. Gaussian pre-filtering coupled to a real space filtering of derivatives allows accurate predictions up to l=6, while log-log polynomial representation gives accurate solutions at any l. Describing the 21 cm model variety is difficult, so it is relevant to relax assumptions. Pre-filtering gives accurate predictions up to l=3-4, while further filtering or boosting amplification/deamplification method improves the results allowing reasonable estimations. The methods can extend the range of realistic background models manageable with a fast computation.","Wed, 10 Jan 2024 14:56:06 UTC (435 KB)"
"82","Exploring Attack Resilience in Distributed Platoon Controllers with Model Predictive Control","Tashfique Hasnine Choudhury","Systems and Control (eess.SY)","The extensive use of distributed vehicle platoon controllers has resulted in several benefits for transportation systems, such as increased traffic flow, fuel efficiency, and decreased pollution. The rising reliance on interconnected systems and communication networks, on the other hand, exposes these controllers to potential cyber-attacks, which may compromise their safety and functionality. This thesis aims to improve the security of distributed vehicle platoon controllers by investigating attack scenarios and assessing their influence on system performance. Various attack techniques, including man-in-the-middle (MITM) and false data injection (FDI), are simulated using Model Predictive Control (MPC) controller to identify vulnerabilities and weaknesses of the platoon controller. Countermeasures are offered and tested, that includes attack analysis and reinforced communication protocols using Machine Learning techniques for detection. The findings emphasize the significance of integrating security issues into their design and implementation, which helps to construct safe and resilient distributed platoon controllers.","Mon, 8 Jan 2024 20:27:16 UTC (1,329 KB)"
"83","Air Quality Forecasting Using Machine Learning: A Global perspective with Relevance to Low-Resource Settings","Mulomba Mukendi Christian, Hyebong Choi","Machine Learning (cs.LG)","Air pollution stands as the fourth leading cause of death globally. While extensive research has been conducted in this domain, most approaches rely on large datasets when it comes to prediction. This limits their applicability in low-resource settings though more vulnerable. This study addresses this gap by proposing a novel machine learning approach for accurate air quality prediction using two months of air quality data. By leveraging the World Weather Repository, the meteorological, air pollutant, and Air Quality Index features from 197 capital cities were considered to predict air quality for the next day. The evaluation of several machine learning models demonstrates the effectiveness of the Random Forest algorithm in generating reliable predictions, particularly when applied to classification rather than regression, approach which enhances the model's generalizability by 42%, achieving a cross-validation score of 0.38 for regression and 0.89 for classification. To instill confidence in the predictions, interpretable machine learning was considered. Finally, a cost estimation comparing the implementation of this solution in high-resource and low-resource settings is presented including a tentative of technology licensing business model. This research highlights the potential for resource-limited countries to independently predict air quality while awaiting larger datasets to further refine their predictions.","Tue, 9 Jan 2024 05:52:02 UTC (427 KB)"
"84","The TNG50-SKIRT Atlas: post-processing methodology and first data release","Maarten Baes, Andrea Gebek, Ana Trcka, Peter Camps, Arjen van der Wel, Abdurro'uf, Nick Andreadis, Sena Bokona Tulu, Abdissa Tassama Emana, Jacopo Fritz, Raymond Kelly, Inja Kovacic, Antonio La Marca, Marco Martorano, Aleksandr Mosenkov, Angelos Nersesian, Vicente Rodriguez-Gomez, Crescenzo Tortora, Bert Vander Meulen, Lingyu Wang","Astrophysics of Galaxies (astro-ph.GA)","Galaxy morphology is a powerful diagnostic to assess the realism of cosmological hydrodynamical simulations. Determining the morphology of simulated galaxies requires the generation of synthetic images through 3D radiative transfer post-processing that properly accounts for different stellar populations and interstellar dust attenuation. We use the SKIRT code to generate the TNG50-SKIRT Atlas, a synthetic UV to near-infrared broadband image atlas for a complete stellar-mass selected sample of 1154 galaxies extracted from the TNG50 cosmological simulation at $z=0$. The images have a high spatial resolution (100 pc) and a wide field of view (160 kpc). In addition to the dust-obscured images, we also release dust-free images and physical parameter property maps with matching characteristics. As a sanity check and preview application we discuss the UVJ diagram of the galaxy sample. We investigate the effect of dust attenuation on the UVJ diagram and find that it affects both the star-forming and the quiescent galaxy populations. The quiescent galaxy region is polluted by younger and star-forming highly inclined galaxies, while dust attenuation induces a separation in inclination of the star-forming galaxy population, with low-inclination galaxies remaining at the blue side of the diagram and high-inclination galaxies systematically moving towards the red side. This image atlas can be used for a variety of other applications, including galaxy morphology studies and the investigation of local scaling relations. We publicly release the images and parameter maps, and we invite the community to use them.","Mon, 8 Jan 2024 20:27:51 UTC (5,255 KB)"
"85","Forecasting hospital discharges for respiratory conditions in Costa Rica using climate and pollution data","Shu Wei Chou-Chen, Luis A. Barboza","Applications (stat.AP)","Respiratory diseases represent one of the most significant economic burdens on healthcare systems worldwide. The variation in the increasing number of cases depends greatly on climatic seasonal effects, socioeconomic factors, and pollution. Therefore, understanding these variations and obtaining precise forecasts allows health authorities to make correct decisions regarding the allocation of limited economic and human resources. This study aims to model and forecast weekly hospitalizations due to respiratory conditions in seven regional hospitals in Costa Rica using four statistical learning techniques (Random Forest, XGboost, Facebook's Prophet forecasting model, and an ensemble method combining the above methods), along with 22 climate change indices and aerosol optical depth as an indicator of pollution. Models are trained using data from 2000 to 2018 and are evaluated using data from 2019 as testing data. Reliable predictions are obtained for each of the seven regional hospitals","Sat, 6 Jan 2024 00:47:44 UTC (194 KB)"
"86","Carbon envelopes around merging galaxies at z ~ 4.5","C. Di Cesare, M. Ginolfi, L. Graziani, R. Schneider, M. Romano, G. Popping","Astrophysics of Galaxies (astro-ph.GA)","Galaxies evolve through a dynamic exchange of material with their immediate surrounding environment, the circumgalactic medium (CGM). Understanding the physics of gas flows and the nature of the CGM is thus fundamental to studying galaxy evolution, especially at $4 \leq z \leq 6$ when galaxies rapidly assembled their masses and reached their chemical maturity. Galactic outflows are predicted to enrich the CGM with metals, although gas stripping in systems undergoing a major merger has also been suggested to play a role. In this work, we explore the metal enrichment of the medium around merging galaxies at $z\sim4.5$, observed by the ALMA Large Program to INvestigate [CII] at Early times (ALPINE) survey. To do so, we study the nature of the [CII]158 $\mu$m emission in the CGM around these systems, using simulations to help disentangle the mechanisms contributing to the CGM metal pollution. By adopting an updated classification of major merger systems in the ALPINE survey, we select and analyse merging galaxies whose components can be spatially and/or spectrally resolved in a robust way. In this way, we can distinguish between the [CII] emission coming from the single components of the system and that coming from the system as a whole. We also make use of the dustyGadget cosmological simulation to select synthetic analogues of observed galaxies and guide the interpretation of the observational results. We find a large diffuse [CII] envelope (> 20 kpc) embedding all the merging systems, with around 50% of the total [CII] emission coming from the medium between the galaxies. Using predictions from dustyGadget we suggest that this emission has a two-fold nature: it is due to both dynamical interactions between the galaxies which result in tidal stripped gas and the presence of star-forming satellites (currently unresolved by ALMA) that enrich the medium with heavy elements.","Fri, 5 Jan 2024 19:00:02 UTC (2,162 KB)[v2] Tue, 9 Jan 2024 11:14:27 UTC (2,140 KB)"
"87","Penalized Distributed Lag Interaction Model: Air Pollution, Birth Weight and Neighborhood Vulnerability","Danielle Demateis, Kayleigh P. Keller, David Rojas-Rueda, Marianthi-Anna Kioumourtzoglou, Ander Wilson","Methodology (stat.ME)","Maternal exposure to air pollution during pregnancy has a substantial public health impact. Epidemiological evidence supports an association between maternal exposure to air pollution and low birth weight. A popular method to estimate this association while identifying windows of susceptibility is a distributed lag model (DLM), which regresses an outcome onto exposure history observed at multiple time points. However, the standard DLM framework does not allow for modification of the association between repeated measures of exposure and the outcome. We propose a distributed lag interaction model that allows modification of the exposure-time-response associations across individuals by including an interaction between a continuous modifying variable and the exposure history. Our model framework is an extension of a standard DLM that uses a cross-basis, or bi-dimensional function space, to simultaneously describe both the modification of the exposure-response relationship and the temporal structure of the exposure data. Through simulations, we showed that our model with penalization out-performs a standard DLM when the true exposure-time-response associations vary by a continuous variable. Using a Colorado, USA birth cohort, we estimated the association between birth weight and ambient fine particulate matter air pollution modified by an area-level metric of health and social adversities from Colorado EnviroScreen.","Fri, 5 Jan 2024 18:30:45 UTC (422 KB)[v2] Wed, 21 Feb 2024 17:38:53 UTC (422 KB)"
"88","Interpretable Time Series Models for Wastewater Modeling in Combined Sewer Overflows","Teodor Chiaburu, Felix Biessmann","Machine Learning (cs.LG)","Climate change poses increasingly complex challenges to our society. Extreme weather events such as floods, wild fires or droughts are becoming more frequent, spontaneous and difficult to foresee or counteract. In this work we specifically address the problem of sewage water polluting surface water bodies after spilling over from rain tanks as a consequence of heavy rain events. We investigate to what extent state-of-the-art interpretable time series models can help predict such critical water level points, so that the excess can promptly be redistributed across the sewage network. Our results indicate that modern time series models can contribute to better waste water management and prevention of environmental pollution from sewer systems. All the code and experiments can be found in our repository: this https URL.","Thu, 4 Jan 2024 11:48:27 UTC (4,973 KB)"
"89","Isolation and Characterisation of Polypropylene Microplastic-Utilising Bacterium from the Antarctic Soil","Nur Ain Shuhada Ab Razak, Syahir Habib, Mohd Yunus Abd Shukor, Siti Aisyah Alias, Jerzy Smykla, Nur Adeela Yasid","Biomolecules (q-bio.BM)","Despite its remoteness from other continents, the Antarctic region cannot escape the aftermath of human activities as it is highly influenced by anthropogenic impacts that occur both in the regional and global context. Contamination by microplastics, mostly caused by the improper disposal of plastic waste, is widely recognised as a serious environmental threat due to its ubiquity. In recent years, most researchers have focused on microplastic pollution in the marine ecosystem of Antarctica, while pollution in the terrestrial environment continues to be neglected. This study was conducted to investigate the ability of Antarctic soil bacteria to use polypropylene (PP) microplastics as the sole carbon source. Bushnell Haas (BH) medium inoculated with bacteria and supplemented PP-microplastics as the sole carbon source was used in the utilisation test. In this study, the growth response of Dermacoccus sp. strain AYDL3 was assessed after exposure to PP-microplastics in a basal medium for 40 days. The weight reduction of the polymer was determined to further support the growth response. The highest and lowest weight loss percentages were observed on day 20 (23.0%) and day 10 (7.75%), respectively. Fourier transforms infrared (FTIR) spectroscopy and scanning electron microscopy (SEM) analyses were used to confirm the utilisation of PP-microplastics by strain AYDL3. Results indicate that the soil bacteria possess a mechanism for breaking down microplastics allowing them to utilise plastics as energy sources without any pre-treatment. This emphasises the significance of these soil bacteria to adapt and subsequently manage the plastic fragments in the soil in the future.","Thu, 4 Jan 2024 06:54:56 UTC (791 KB)"
"90","Reconstructing almost all of a point set in $\mathbb{R}^d$ from randomly revealed pairwise distances","Douglas Barnes, Jan Petr, Julien Portier, Benedict Randall Shaw, Alan Sergeev","Combinatorics (math.CO)","Let $V$ be a set of $n$ points in $\mathbb{R}^d$, and suppose that the distance between each pair of points is revealed independently with probability $p$. We study when this information is sufficient to reconstruct large subsets of $V$, up to isometry. Strong results for $d=1$ have been obtained by Girão, Illingworth, Michel, Powierski, and Scott. In this paper, we investigate higher dimensions, and show that if $p>n^{-2/(d+4)}$, then we can reconstruct almost all of $V$ up to isometry, with high probability. We do this by relating it to a polluted graph bootstrap percolation result, for which we adapt the methods of Balogh, Bollobás, and Morris.","Wed, 3 Jan 2024 18:43:33 UTC (25 KB)"
"91","Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review","Ihsane Gryech, Chaimae Assad, Mounir Ghogho, Abdellatif Kobbane","Machine Learning (cs.LG)","According to the World Health Organization (WHO), air pollution kills seven million people every year. Outdoor air pollution is a major environmental health problem affecting low, middle, and high-income countries. In the past few years, the research community has explored IoT-enabled machine learning applications for outdoor air pollution prediction. The general objective of this paper is to systematically review applications of machine learning and Internet of Things (IoT) for outdoor air pollution prediction and the combination of monitoring sensors and input features used. Two research questions were formulated for this review. 1086 publications were collected in the initial PRISMA stage. After the screening and eligibility phases, 37 papers were selected for inclusion. A cost-based analysis was conducted on the findings to highlight high-cost monitoring, low-cost IoT and hybrid enabled prediction. Three methods of prediction were identified: time series, feature-based and spatio-temporal. This review's findings identify major limitations in applications found in the literature, namely lack of coverage, lack of diversity of data and lack of inclusion of context-specific features. This review proposes directions for future research and underlines practical implications in healthcare, urban planning, global synergy and smart cities.","Wed, 3 Jan 2024 15:36:33 UTC (1,417 KB)"
"92","Impact of DG and survey of pricing mechanism around different states in USA","Mohsen Abedi","Systems and Control (eess.SY)","In this paper, we investigate the impact of the Distributed generation (DG) on Power Transmission Grid and pricing strategy for different geographical locations in different states, generally distributed generation (DG) on distribution feeders is known to have an impact on voltage regulation and power quality. A DG might provide voltage and power support in some cases, but most cases cause short term instability voltage, depending on the several variables, including relative DG size and location, power network and load character, so This paper also addressing to the following questions: the different between DG and conventional power station? What are penetration levels of different DG to the power grid and compliances to the IEEE relevant standards, discusses unexpected issues with a special emphasis on power protection coordination problems, potential advantage and disadvantage to using DG while Distributed Generation (DG) allows collection of energy from many sources and may provide lower environmental pollution then we will discuss what would be the main Factors affecting Electricity Prices of DG units at different states.","Tue, 2 Jan 2024 20:55:43 UTC (655 KB)"
"93","A scalable two-stage Bayesian approach accounting for exposure measurement error in environmental epidemiology","Changwoo J. Lee, Elaine Symanski, Amal Rammah, Dong Hun Kang, Philip K. Hopke, Eun Sug Park","Methodology (stat.ME)","Accounting for exposure measurement errors has been recognized as a crucial problem in environmental epidemiology for over two decades. Bayesian hierarchical models offer a coherent probabilistic framework for evaluating associations between environmental exposures and health effects, which take into account exposure measurement errors introduced by uncertainty in the estimated exposure as well as spatial misalignment between the exposure and health outcome data. While two-stage Bayesian analyses are often regarded as a good alternative to fully Bayesian analyses when joint estimation is not feasible, there has been minimal research on how to properly propagate uncertainty from the first-stage exposure model to the second-stage health model, especially in the case of a large number of participant locations along with spatially correlated exposures. We propose a scalable two-stage Bayesian approach, called a sparse multivariate normal (sparse MVN) prior approach, based on the Vecchia approximation for assessing associations between exposure and health outcomes in environmental epidemiology. We compare its performance with existing approaches through simulation. Our sparse MVN prior approach shows comparable performance with the fully Bayesian approach, which is a gold standard but is impossible to implement in some cases. We investigate the association between source-specific exposures and pollutant (nitrogen dioxide (NO$_2$))-specific exposures and birth outcomes for 2012 in Harris County, Texas, using several approaches, including the newly developed method.","Mon, 1 Jan 2024 02:07:26 UTC (2,798 KB)[v2] Sun, 14 Jan 2024 03:29:07 UTC (2,656 KB)"
"94","AClassiHonk: A System Framework to Annotate and Classify Vehicular Honk from Road Traffic","Biswajit Maitya, Abdul Alima, Popuri Sree Rama Charana, Amlan Chakrabartib, Subrata Nandia, Sanghita Bhattacharjeea","Social and Information Networks (cs.SI)","Recent studies emphasize that vehicular honking contributes to over 50% of noise pollution in developing urban and suburban areas. Frequent honking negatively impacts health, road safety, and the environment. Recognizing and classifying different vehicle honks could offer valuable insights into environmental noise pollution. Existing research on outdoor sound classification and honk detection lacks the ability to classify honks based on vehicle types, limiting contextual information inference for locations, areas, or traffic. Therefore, it becomes imperative to design a system that can detect and classify honks of different types of vehicles from which we can infer some contextual information. In this paper, we have developed a novel framework AClassiHonk that performs raw vehicular honk sensing, data labeling and classifies the honk into three major groups, i.e., light-weight vehicles, medium-weight vehicles, and heavy-weight vehicles. We collected the raw audio samples of different vehicular honking based on spatio-temporal characteristics and converted them into spectrogram images. We have proposed a deep learning-based Multi-label Autoencoder model (MAE) for automated labeling of the unlabeled data samples, which provides 97.64% accuracy in contrast to existing deep learning-based data labeling methods. Further, we have used various pre-trained models, namely Inception V3, ResNet50, MobileNet, ShuffleNet, and proposed an Ensembled Transfer Learning model (EnTL) for vehicle honks classification and performed comparative analysis. Results reveal that EnTL exhibits the best performance compared to pre-trained models and achieves 96.72% accuracy in our dataset. In addition, we have identified a context of a location based on these classified honk signatures in a city.","Sat, 30 Dec 2023 06:42:47 UTC (2,593 KB)"
"95","Combined Explanation of LHC Multi-Lepton, Di-Photon and Top-Quark Excesses","Guglielmo Coloretti, Andreas Crivellin, Bruce Mellado","High Energy Physics - Phenomenology (hep-ph)","The LHC analyses of processes containing two or more leptons and missing energy, possibly in association with b-jets, show strong tensions with the Standard Model predictions and are known as multi-lepton anomalies. In particular, top-quark differential distributions point towards the associated production of new Higgs bosons decaying into bottom quarks and W bosons ($>5\sigma$) with masses consistent with the di-photon excesses at 95GeV and 152GeV ($3.8\sigma$ and $4.9\sigma$, respectively). Furthermore, CMS found indications for resonant top-quark pair production at 400GeV ($3.5\sigma$) and both ATLAS and CMS reported elevated four-top and ttW cross-sections. In this article, we propose a combined explanation of these excesses by supplementing the SM Higgs with a second scalar doublet, a real scalar singlet ($S$) and a Higgs triplet with $Y=0$ ($\Delta$); the $\Delta$2HDMS. We fix the masses of the neutral triplet-like and the singlet-like scalars by the di-photon excesses, i.e. $m_{\Delta^0}=152$GeV and $m_S=95$GeV, respectively. Here, H, the CP-even component of the second doublet, is produced via gluon fusion from a top-loop and decays dominantly to $S+\Delta^0$ whose subsequent decays to WW and bb explain the differential top-quark distributions for $\sigma(pp\to H\to S\Delta^0)\approx6$pb. Fixing the top-Yukawa accordingly, the CP-odd Higgs boson A turns out to have the right production cross-section to account for the resonant top-pair excess at 400GeV, while the top-associated production of H and A results in new physics pollution of Standard Model ttW and four-top cross sections, as preferred by the data. Furthermore, a positive shift in the W mass is naturally induced by the vacuum expectation value of the triplet and we show that the most relevant signal strengths of the 152GeV boson are compatible with the process $pp\to H\to \Delta^0S$ if S is allowed to decay invisibly.","Thu, 28 Dec 2023 19:00:00 UTC (2,193 KB)"
"96","Towards a Microservice-based Middleware for a Multi-hazard Early Warning System","A Akanbi","Distributed, Parallel, and Cluster Computing (cs.DC)","Environmental hazards like water and air pollution, extreme weather, or chemical exposures can affect human health in a number of ways, and it is a persistent apprehension in communities surrounded by mining operations. The application of modern technologies in the environmental monitoring of these Human-made hazards is critical, because while not immediately health-threatening may turn out detrimental with unwanted negative effects. Enabling technologies needed to realise this concept is multifaceted and most especially involves deploying interconnected Internet of Things (IoT) sensors, existing legacy systems, enterprise networks, multi layered software architecture (middleware), and event processing engines, amongst others. Currently, the integration of several early warning systems has inherent challenges, mostly due to the heterogeneity of components. This paper proposes transversal microservice-based middleware aiming at increasing data integration, interoperability, scalability, high availability, and reusability of adopted systems using a container orchestration framework for a multi-hazard early warning system. Devised within the scope of the ICMHEWS project, the proposed platform aims at improving known challenges.","Sat, 23 Dec 2023 18:50:58 UTC (609 KB)"
"97","GreenScan: Towards large-scale monitoring the health of urban trees using mobile sensing","Akshit Gupta, Simone Mora, Fan Zhang, Martine Rutten, R. Venkatesha Prasad, Carlo Ratti","Systems and Control (eess.SY)","Healthy urban greenery is a fundamental asset to mitigate climate change phenomenons such as extreme heat and air pollution. However, urban trees are often affected by abiotic and biotic stressors that hamper their functionality, and whenever not timely managed, even their survival. While current visual or instrumented inspection techniques can help take effective measures, they often require a high amount of human labor, making frequent assessments infeasible at a city-wide scale. In this paper, we present GreenScan, a ground-based sensing system designed to provide health assessment of urban trees at high spatio-temporal resolutions, with low costs. The system utilises thermal and multi-spectral imaging sensors fused using custom computer vision models in order to estimate two tree health indexes. The evaluation of the system was performed through data collection experiments in Cambridge, USA. Overall, this approach illustrates the potential of autonomous mobile ground-based tree health monitoring on city-wide scales at high temporal resolutions with low-costs.","Fri, 22 Dec 2023 01:36:39 UTC (17,466 KB)"
"98","Implied CO$_{\textbf{2}}$-Price and Interest Rate of Carbon","Christian P. Fries","Mathematical Finance (q-fin.MF)","By its nature, the so-called social cost of carbon (SCC(t)) will likely not cover the cost induced by climate change (damage cost and abatement cost) if it is used as a CO$_2$-price. It is a marginal price only. We define an implied CO$_2$-price that covers the climate change-induced costs. The price can be interpreted as a \textit{polluter pays principle}. A numerical analysis using a classical DICE model reveals that the cost-implied CO$_2$ price is around 500 \$/tCO$_2$, while the corresponding price associated with the SCC is about 50 \$/tCO$_2$. In addition, we define the internal rate of return of carbon abatement and calculate it for the classical DICE model. This rate is much higher than the model's discount rate, which may suggest the advantage of financing abatement by loans.","Wed, 20 Dec 2023 21:55:26 UTC (32 KB)[v2] Sat, 23 Dec 2023 12:08:36 UTC (75 KB)[v3] Thu, 4 Jan 2024 09:55:53 UTC (83 KB)[v4] Sun, 14 Jan 2024 22:01:09 UTC (84 KB)[v5] Mon, 29 Jan 2024 07:15:07 UTC (128 KB)"
"99","A 3D super-resolution of wind fields via physics-informed pixel-wise self-attention generative adversarial network","Takuya Kurihana, Kyongmin Yeo, Daniela Szwarcman, Bruce Elmegreen, Karthik Mukkavilli, Johannes Schmude, Levente Klein","Atmospheric and Oceanic Physics (physics.ao-ph)","To mitigate global warming, greenhouse gas sources need to be resolved at a high spatial resolution and monitored in time to ensure the reduction and ultimately elimination of the pollution source. However, the complexity of computation in resolving high-resolution wind fields left the simulations impractical to test different time lengths and model configurations. This study presents a preliminary development of a physics-informed super-resolution (SR) generative adversarial network (GAN) that super-resolves the three-dimensional (3D) low-resolution wind fields by upscaling x9 times. We develop a pixel-wise self-attention (PWA) module that learns 3D weather dynamics via a self-attention computation followed by a 2D convolution. We also employ a loss term that regularizes the self-attention map during pretraining, capturing the vertical convection process from input wind data. The new PWA SR-GAN shows the high-fidelity super-resolved 3D wind data, learns a wind structure at the high-frequency domain, and reduces the computational cost of a high-resolution wind simulation by x89.7 times.","Wed, 20 Dec 2023 17:28:21 UTC (362 KB)"
"100","Long term variability of light-pollution in Bisei Town","Ryosuke Itoh, Syota Maeno","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Bisei town, located in the west part of Japan, is known as a place where the local community protects its beautiful night sky from light pollution through its unique ordinances and the efforts of the local residents. It is also important to monitor in the quantity and quality of light pollution for precise measurement of astronomical observations. The fluorescent lamps in the city were gradually replaced with light emitting diode (LED) lamps. In order to investigate how much light pollution is affecting astronomical observation, we analyzed the archival photometric and spectroscopic data taken by the 101cm telescope that has been installed at Bisei Astronomical Observatory (BAO) since 2006. As a result, we found that there is no significant variability in sky brightness in optical bands, but from spectroscopic observation, we observed a blue humps around 4500 Åoriginating from LED lights from 2017 to 2023. The brightness of light pollution observed at BAO is not varied but the origin of light has gradually changed from fluorescent lamps to LED lamps.","Wed, 20 Dec 2023 07:28:57 UTC (290 KB)"
"101","Modelling and characterization of fine Particulate Matter dynamics in Bujumbura using low cost sensors","Egide Ndamuzi, Rachel Akimana, Paterne Gahungu, Elie Bimenyimana","Machine Learning (stat.ML)","Air pollution is a result of multiple sources including both natural and anthropogenic activities. The rapid urbanization of the cities such as Bujumbura economic capital of Burundi, is one of these factors. The very first characterization of the spatio-temporal variability of PM2.5 in Bujumbura and the forecasting of PM2.5 concentration have been conducted in this paper using data collected during a year, from august 2022 to august 2023, by low cost sensors installed in Bujumbura city. For each commune, an hourly, daily and seasonal analysis were carried out and the results showed that the mass concentrations of PM2.5 in the three municipalities differ from one commune to another. The average hourly and annual PM2.5 concentrations exceed the World Health Organization standards. The range is between 28.3 and 35.0 microgram/m3 . In order to make prediction of PM2.5 concentration, an investigation of RNN with Long Short Term Memory (LSTM) has been undertaken.","Tue, 19 Dec 2023 09:51:02 UTC (1,393 KB)"
"102","Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment","Fengli Xu, Jun Zhang, Chen Gao, Jie Feng, Yong Li","Artificial Intelligence (cs.AI)","Urban environments, characterized by their complex, multi-layered networks encompassing physical, social, economic, and environmental dimensions, face significant challenges in the face of rapid urbanization. These challenges, ranging from traffic congestion and pollution to social inequality, call for advanced technological interventions. Recent developments in big data, artificial intelligence, urban computing, and digital twins have laid the groundwork for sophisticated city modeling and simulation. However, a gap persists between these technological capabilities and their practical implementation in addressing urban challenges in an systemic-intelligent way. This paper proposes Urban Generative Intelligence (UGI), a novel foundational platform integrating Large Language Models (LLMs) into urban systems to foster a new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model trained on city-specific multi-source data, to create embodied agents for various urban tasks. These agents, operating within a textual urban environment emulated by city simulator and urban knowledge graph, interact through a natural language interface, offering an open platform for diverse intelligent and embodied agent development. This platform not only addresses specific urban issues but also simulates complex urban systems, providing a multidisciplinary approach to understand and manage urban complexity. This work signifies a transformative step in city science and urban intelligence, harnessing the power of LLMs to unravel and address the intricate dynamics of urban systems. The code repository with demonstrations will soon be released here this https URL.","Tue, 19 Dec 2023 03:12:13 UTC (2,493 KB)"
"103","Towards a Spectro-Photometric Characterization of the Chilean Night Sky. A first quantitative assessment of ALAN across the Coquimbo Region","Rodolfo Angeloni (1), Juan Pablo Uchima Tamayo (2,1), Marcelo Jaque Arancibia (2,3), Roque Ruiz-Carmona (1), Diego Fernandez Olivares (2), Pedro Sanhueza (4), Guillermo Damke (5), Ricardo Moyano (2), Veronica Firpo (1), Javier Fuentes (6), Javier Sayago (7) ((1) Gemini Observatory, NSF's NOIRLab, (2) Departamento de Astronomía, Universidad de La Serena, (3) Instituto Multidisciplinario de Investigación y Postgrado, (4) Dirección de Energía, Ciencia y Tecnología e Innovación, Ministerio Relaxiones Exteriores, (5) Cerro Tololo Interamerican Observatory, NSF's NOIRLab, (6) European Southern Observatory, (7) OPCC, NSF's NOIRLab)","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Light pollution is recognized as a global issue that, like other forms of anthropogenic pollution, has significant impact on ecosystems and adverse effects on living organisms. Multiple evidence suggests that it has been increasing at an unprecedented rate at all spatial scales. Chile, which thanks to its unique environmental conditions has become one of the most prominent astronomical hubs of the world, seems to be no exception. In this paper we present the results of the first observing campaign aimed at quantifying the effects of artificial lights at night (ALAN) on the brightness and colors of Chilean sky. Through the analysis of photometrically calibrated all-sky images captured at four representative sites with an increasing degree of anthropization, and the comparison with state-of-the-art numerical models, we show that significant levels of light pollution have already altered the appearance of the natural sky even in remote areas. Our observations reveal that the light pollution level recorded in a small town of the Coquimbo Region is comparable with that of Flagstaff, a ten times larger Dark Sky city, and that a mid-size urban area door to the Atacama Desert displays photometric indicators of night sky quality that are typical of the most densely populated regions of Europe. Our results suggest that there is still much to be done in Chile to keep the light pollution phenomenon under control and thus preserve the darkness of its night sky - a natural and cultural heritage that is our responsibility to protect.","Sat, 16 Dec 2023 21:04:21 UTC (16,870 KB)"
"104","Atomic Diffusion and Mixing in Old Stars VIII: Chemical abundance variations in the globular cluster M4 (NGC 6121)","T. Nordlander, P. Gruyters, O. Richard, A. J. Korn","Solar and Stellar Astrophysics (astro-ph.SR)","Variations in chemical abundances with evolutionary phase have been identified among stars in globular and open clusters with a wide range of metallicities. In the metal-poor clusters, these variations compare well with predictions from stellar structure and evolution models considering the internal diffusive motions of atoms and ions, collectively known as atomic diffusion, when moderated by an additional mixing process with a fine-tuned efficiency. We present here an investigation of these effects in the Galactic globular cluster NGC 6121 (M4) ([Fe/H] = -1.13) through a detailed chemical abundance analysis of 86 stars using high-resolution ESO/VLT FLAMES spectroscopy. The stars range from the main-sequence turnoff point (TOP) to the red giant branch (RGB) just above the bump. We identify C-N-O and Mg-Al-Si abundance anti-correlations, and confirm the presence of a bimodal population differing by 1 dex in nitrogen abundance. The composition of the second-generation stars imply pollution from both massive (20-40 Msol) and asymptotic giant branch stars. We find evolutionary variations in chemical abundances between the TOP and RGB, which are robust to uncertainties in stellar parameters and modelling assumptions. The variations are weak, but match predictions well when employing efficient additional mixing. Without correcting for Galactic production of lithium, we derive an initial lithium abundance 2.63+-0.10, which is marginally lower than the predicted primordial BBN value.","Fri, 15 Dec 2023 10:12:40 UTC (395 KB)"
"105","Enhanced optical, structural and antibacterial properties of ZnO doped TiO2 composites","Mehmet Eymen Sumer, Bengu Ozugur Uysal","Materials Science (cond-mat.mtrl-sci)","Bacterial infections are a common problem in daily life that can affect human health. Researchers are looking for valuable materials that can help prevent such infections and environmental pollutants. Thin films are a well-known application for photocatalytic and biological activity. Therefore, thin-film formation is an excellent way to address these problems, thanks to its nanosized thickness and enhanced monolayer or multilayered structure. Titanium oxide (TiO2) is the most common material used to produce thin films due to its various traits that enhance the activity of thin films, such as structural and optical properties. However, the single usage of pure TiO2 has certain limitations over these problems. Therefore, new techniques, called doping, need to be implemented to overcome these limitations. Doping is a standard method for manipulating material properties to provide enhanced functionality. ZnO was selected as a dopant because of its good bandgap energy and high electron activity. Thus, this research mainly focused on the differences in antibacterial, structural, and optical activity between pure TiO2 and ZnO-doped TiO2. The sol-gel method was used in this research for several different thin-film deposition methods due to its easy progression at room temperature, low cost, and homogeneity traits. The antibacterial activity of pure and doped TiO2 thin films was analyzed using the standard ISO 22196 protocol against gram-positive Staphylococcus aureus and gram-negative Escherichia coli. As a result, XRD and UV-vis spectrophotometer measurements show that our dopant ZnO efficiently enhances the bandgap energy of pure TiO2. The correlation between dispersibility and homogeneity was achieved in the concentration range ZTA-B-R (5-10).","Thu, 14 Dec 2023 21:02:21 UTC (1,360 KB)"
"106","INRISCO: INcident monitoRing In Smart COmmunities","Mónica Aguilar Igartua, Florina Almenares, Rebeca P. Díaz Redondo, Manuela I. Martín, Jordi Forné, Celeste Campo, Ana Fernández, Luis J. de la Cruz, Carlos García-Rubio, Andrés Marínn, Ahmad Mohamad Mezher, Daniel Díaz, Héctor Cerezo, David Rebollo-Monedero, Patricia Arias, Francisco Rico","Networking and Internet Architecture (cs.NI)","Major advances in information and communication technologies (ICTs) make citizens to be considered as sensors in motion. Carrying their mobile devices, moving in their connected vehicles or actively participating in social networks, citizens provide a wealth of information that, after properly processing, can support numerous applications for the benefit of the community. In the context of smart communities, the INRISCO proposal intends for (i) the early detection of abnormal situations in cities (i.e., incidents), (ii) the analysis of whether, according to their impact, those incidents are really adverse for the community; and (iii) the automatic actuation by dissemination of appropriate information to citizens and authorities. Thus, INRISCO will identify and report on incidents in traffic (jam, accident) or public infrastructure (e.g., works, street cut), the occurrence of specific events that affect other citizens life (e.g., demonstrations, concerts), or environmental problems (e.g., pollution, bad weather). It is of particular interest to this proposal the identification of incidents with a social and economic impact, which affects the quality of life of citizens.","Tue, 12 Dec 2023 23:09:22 UTC (2,606 KB)"
"107","Molecular sieve vacuum swing adsorption purification and radon reduction system for gaseous dark matter and rare-event detectors","R.R. Marcelo Gregorio, N.J.C. Spooner, F. Dastgiri, A. C. Ezeribe, G. Lane, A.G. McLean, K. Miuchi, H. Ogawa","Instrumentation and Detectors (physics.ins-det)","In the field of directional dark matter experiments, SF6 has emerged as an ideal target gas. A critical challenge with this gas, and with other proposed gases, is the effective removal of contaminant gases. This includes radon which produce unwanted background events, but also common pollutants such as water, oxygen, and nitrogen, which can capture ionisation electrons, resulting in loss of detector gas gain over time. We present here a novel molecular sieve (MS) based gas recycling system for the simultaneous removal of both radon and common pollutants from SF6. The apparatus has the additional benefit of minimising gas required in experiments and utilises a Vacuum Swing Adsorption (VSA) technique for continuous, long-term operation. The gas system's capabilities were tested with a 100 L low-pressure SF6 Time Projection Chamber (TPC) detector. For the first time, we present a newly developed low-radioactive MS type 5A. This material was found to emanate radon at 98% less per radon captured compared to commercial counterparts, the lowest known MS emanation at the time of writing. Consequently, the radon activity in the TPC detector was reduced, with an upper limit of less than 7.2 mBq at a 95% confidence level (C.L.). Incorporation of MS types 3A and 4A to absorb common pollutants was found successfully to mitigate against gain deterioration while recycling the target gas.","Tue, 12 Dec 2023 20:26:00 UTC (24,491 KB)[v2] Wed, 31 Jan 2024 16:48:59 UTC (24,491 KB)"
"108","Privacy-Aware Energy Consumption Modeling of Connected Battery Electric Vehicles using Federated Learning","Sen Yan, Hongyuan Fang, Ji Li, Tomas Ward, Noel O'Connor, Mingming Liu","Machine Learning (cs.LG)","Battery Electric Vehicles (BEVs) are increasingly significant in modern cities due to their potential to reduce air pollution. Precise and real-time estimation of energy consumption for them is imperative for effective itinerary planning and optimizing vehicle systems, which can reduce driving range anxiety and decrease energy costs. As public awareness of data privacy increases, adopting approaches that safeguard data privacy in the context of BEV energy consumption modeling is crucial. Federated Learning (FL) is a promising solution mitigating the risk of exposing sensitive information to third parties by allowing local data to remain on devices and only sharing model updates with a central server. Our work investigates the potential of using FL methods, such as FedAvg, and FedPer, to improve BEV energy consumption prediction while maintaining user privacy. We conducted experiments using data from 10 BEVs under simulated real-world driving conditions. Our results demonstrate that the FedAvg-LSTM model achieved a reduction of up to 67.84\% in the MAE value of the prediction results. Furthermore, we explored various real-world scenarios and discussed how FL methods can be employed in those cases. Our findings show that FL methods can effectively improve the performance of BEV energy consumption prediction while maintaining user privacy.","Tue, 12 Dec 2023 15:40:38 UTC (18,142 KB)"
"109","Interactive effects of multiple stressors in coastal ecosystems","Shubham Krishna, Carsten Lemmen, Serra Örey, Jennifer Rehren, Julien Di Pane, Moritz Mathis, Miriam Püts, Sascha Hokamp, Himansu Pradhan, Matthias Hasenbein, Jürgen Scheffran, Kai Wirtz","Quantitative Methods (q-bio.QM)","Coastal ecosystems are increasingly experiencing anthropogenic pressures such as climate heating, CO2 increase, metal and organic pollution, overfishing and resource extraction. Some resulting stressors are more direct like fisheries, others more indirect like ocean acidification, yet they jointly affect marine biota, communities and entire ecosystems. While single-stressor effects have been widely investigated, the interactive effects of multiple stressors on ecosystems are less researched. In this study, we review the literature on multiple stressors and their interactive effects in coastal environments across organisms. We classify the interactions into three categories: synergistic, additive, and antagonistic. We found phytoplankton and mollusks to be the most studied taxonomic groups. The stressor combinations of climate warming, ocean acidification, eutrophication, and metal pollution are the most critical for coastal ecosystems as they exacerbate adverse effects on physiological traits such as growth rate, basal respiration, and size. Phytoplankton appears to be most sensitive to interactions between metal and nutrient pollution. In nutrient-enriched environments, the presence of metals considerably affects the uptake of nutrients, and increases respiration costs and toxin production in phytoplankton. For mollusks, warming and low pH are the most lethal stressors. The combined effect of heat stress and ocean acidification leads to decreased growth rate, shell size, and acid-base regulation capacity in mollusks. However, for a holistic understanding of how coastal food webs will evolve with ongoing changes, we suggest more research on ecosystem-level responses. This can be achieved by combining in-situ observations from controlled environments (e.g. mesocosm experiments) with modelling approaches.","Tue, 12 Dec 2023 14:25:26 UTC (1,680 KB)"
"110","On One Dimensional Advection -- Diffusion Equation with Variable Diffusivity","Eeshwar Prasad Poudel, Pitambar Acharya, Jeevan Kafle, Shreeram Khadka","Analysis of PDEs (math.AP)","In this paper, we address a time-dependent one-dimensional linear advection-diffusion equation with Dirichlet homogeneous boundary conditions. The equation is solved both analytically, using separation of variables, and numerically, employing the finite difference method. The computational output includes three dimensional (3D) plots for solutions, focusing on pollutants such as Ammonia, Carbon monoxide, Carbon dioxide, and Sulphur dioxide. Concentrations, along with their respective diffusivities, are analyzed through 3D plots and actual calculations. To comprehend the diffusivity-concentration relationship for predicting pollutant movement in the air, the domain is divided into two halves. The study explores the behavior of pollutants with higher diffusivity entering regions with lower diffusivity, and vice versa, using 2D and 3D plots. This task is crucial for effective pollution control strategies, and safeguarding the environment and public health.","Mon, 11 Dec 2023 16:18:50 UTC (1,927 KB)"
"111","Parametrically enhancing sensor sensitivity at an exceptional point","P. Djorwé, M. Asjad, Y. Pennec, D. Dutykh, B. Djafari-Rouhani","Quantum Physics (quant-ph)","We propose a scheme to enhance the sensitivity of Non-Hermitian optomechanical mass-sensors. The benchmark system consists of two coupled optomechanical systems where the mechanical resonators are mechanically coupled. The optical cavities are driven either by a blue or red detuned laser to produce gain and loss, respectively. Moreover, the mechanical resonators are parametrically driven through the modulation of their spring constant. For a specific strength of the optical driving field and without parametric driving, the system features an Exceptional Point (EP). Any perturbation to the mechanical frequency (dissipation) induces a splitting (shifting) of the EP, which scales as the square root of the perturbation strength, resulting in a sensitivity-factor enhancement compared with conventional optomechanical sensors. The sensitivity enhancement induced by the shifting scenario is weak as compared to the one based on the splitting phenomenon. By switching on parametric driving, the sensitivity of both sensing schemes is greatly improved, yielding to a better performance of the sensor. We have also confirmed these results through an analysis of the output spectra and the transmissions of the optical cavities. In addition to enhancing EP sensitivity, our scheme also reveals nonlinear effects on sensing under splitting and shifting scenarii. This work sheds light on new mechanisms of enhancing the sensitivity of Non-Hermitian mass sensors, paving a way to improve sensors performance for better nanoparticles or pollutants detection, and for water treatment.","Fri, 8 Dec 2023 14:25:18 UTC (424 KB)[v2] Tue, 12 Dec 2023 08:29:54 UTC (424 KB)[v3] Sat, 13 Jan 2024 13:29:42 UTC (411 KB)"
"112","Application of machine learning technique for a fast forecast of aggregation kinetics in space-inhomogeneous systems","M.A. Larchenko, R.R. Zagidullin, V.V. Palyulin, N.V. Brilliantov","Computational Physics (physics.comp-ph)","Modeling of aggregation processes in space-inhomogeneous systems is extremely numerically challenging since complicated aggregation equations -- Smoluchowski equations are to be solved at each space point along with the computation of particle propagation. Low rank approximation for the aggregation kernels can significantly speed up the solution of Smoluchowski equations, while particle propagation could be done in parallel. Yet the simulations with many aggregate sizes remain quite resource-demanding. Here, we explore the way to reduce the amount of direct computations with the use of modern machine learning (ML) techniques. Namely, we propose to replace the actual numerical solution of the Smoluchowki equations with the respective density transformations learned with the application of the conditional normalising flow. We demonstrate that the ML predictions for the space distribution of aggregates and their size distribution requires drastically less computation time and agrees fairly well with the results of direct numerical simulations. Such an opportunity of a quick forecast of space-dependent particle size distribution could be important in practice, especially for the online prediction and visualisation of pollution processes, providing a tool with a reasonable tradeoff between the prediction accuracy and the computational time.","Thu, 7 Dec 2023 19:50:40 UTC (573 KB)"
"113","Short-term prediction of construction waste transport activities using AI-Truck","Meng Xu, Ke Han","Machine Learning (cs.LG)","Construction waste hauling trucks (or `slag trucks') are among the most commonly seen heavy-duty vehicles in urban streets, which not only produce significant NOx and PM emissions but are also a major source of on-road and on-site fugitive dust. Slag trucks are subject to a series of spatial and temporal access restrictions by local traffic and environmental policies. This paper addresses the practical problem of predicting slag truck activity at a city scale during heavy pollution episodes, such that environmental law enforcement units can take timely and proactive measures against localized truck aggregation. A deep ensemble learning framework (coined AI-Truck) is designed, which employs a soft vote integrator that utilizes BI-LSTM, TCN, STGCN, and PDFormer as base classifiers to predict the level of slag truck activities at a resolution of 1km$\times$1km, in a 193 km$^2$ area in Chengdu, China. As a classifier, AI-Truck yields a Macro f1 close to 80\% for 0.5h- and 1h-prediction.","Thu, 7 Dec 2023 13:38:55 UTC (4,855 KB)"
"114","Simulating the Air Quality Impact of Prescribed Fires Using a Graph Neural Network-Based PM$_{2.5}$ Emissions Forecasting System","Kyleen Liao, Jatan Buch, Kara Lamb, Pierre Gentine","Atmospheric and Oceanic Physics (physics.ao-ph)","The increasing size and severity of wildfires across western North America have generated dangerous levels of PM$_{2.5}$ pollution in recent years. In a warming climate, expanding the use of prescribed fires is widely considered to be the most robust fire mitigation strategy. However, reliably forecasting the potential air quality impact from these prescribed fires, a critical ingredient in determining the fires' location and time, at hourly to daily time scales remains a challenging problem. This paper proposes a novel integration of prescribed fire simulation with a spatio-temporal graph neural network-based PM$_{2.5}$ forecasting model. The experiments in this work focus on determining the optimal time for implementing prescribed fires in California as well as quantifying the potential air quality trade-offs involved in conducting more prescribed fires outside the fire season.","Thu, 7 Dec 2023 13:18:36 UTC (2,006 KB)"
"115","A Nearby Polluted White Dwarf with a 6.2 h Spin Period","J. Farihi, A. Robert, N. Walters","Solar and Stellar Astrophysics (astro-ph.SR)","This letter reports the first detection of a periodic light curve whose modulation is unambiguously due to rotation in a polluted white dwarf. TESS observations of WD 2138-332, at a distance of 16.1 pc, reveal a 0.39 per cent amplitude modulation with a 6.19 h period. While this rotation is relatively rapid for isolated white dwarfs, it falls within the range of spin periods common to those with detectable magnetic fields, where WD 2138-332 is notably both metal-rich and weakly magnetic. Within the local 20 pc volume of white dwarfs, multi-sector TESS data find no significant periodicities among the remaining 16 polluted objects (five of which are also magnetic), whereas six of 23 magnetic and metal-free targets have light curves consistent with rotation periods between 0.7 and 35 h (three of which are new discoveries). This indicates the variable light curve of WD 2138-332 is primarily a result of magnetism, as opposed to an inhomogeneous distribution of metals. From 13 magnetic and metallic degenerates with acceptable TESS data, a single detection of periodicity suggests that polluted white dwarfs are not rotating as rapidly as their magnetic counterparts, and planet ingestion is thus unlikely to be a significant channel for rapid rotation.","Wed, 6 Dec 2023 19:01:06 UTC (141 KB)[v2] Fri, 19 Jan 2024 16:35:02 UTC (143 KB)[v3] Thu, 1 Feb 2024 14:53:29 UTC (143 KB)"
"116","Impact of carbon market on production emissions","Arash Fahim, Nizar Touzi","Optimization and Control (math.OC)","The aim of this paper is to address the effect of the carbon emission allowance market on the production policy of a large polluter production firm. We investigate this effect in two cases; when the large polluter cannot affect the risk premium of the allowance market, and when it can change the risk premium by its production. In this simple model, we ignore any possible investment of the firm in pollution reducing technologies. We formulate the problem of optimal production by a stochastic optimization problem. Then, we show that, as expected, the market reduces the optimal production policy in the first case if the firm is not given a generous initial cheap allowance package. However, when the large producer activities can change the market risk premium, the cut on the production and consequently pollution cannot be guaranteed. In fact, there are cases in this model when the optimal production is {\it always} larger than expected, and an increase in production, and thus pollution, can increase the profit of the firm. We conclude that some of the parameters of the market which contribute to this effect can be wisely controlled by the regulators in order to diminish this manipulative behavior of the firm.","Wed, 6 Dec 2023 18:33:59 UTC (1,691 KB)"
"117","Higher-order FEM and CIP-FEM for Helmholtz equation with high wave number and perfectly matched layer truncation","Yonglin Li, Haijun Wu","Numerical Analysis (math.NA)","The high-frequency Helmholtz equation on the entire space is truncated into a bounded domain using the perfectly matched layer (PML) technique and subsequently, discretized by the higher-order finite element method (FEM) and the continuous interior penalty finite element method (CIP-FEM). By formulating an elliptic problem involving a linear combination of a finite number of eigenfunctions related to the PML differential operator, a wave-number-explicit decomposition lemma is proved for the PML problem, which implies that the PML solution can be decomposed into a non-oscillating elliptic part and an oscillating but analytic part. The preasymptotic error estimates in the energy norm for both the $p$-th order CIP-FEM and FEM are proved to be $C_1(kh)^p + C_2k(kh)^{2p} +C_3 E^{\rm PML}$ under the mesh condition that $k^{2p+1}h^{2p}$ is sufficiently small, where $k$ is the wave number, $h$ is the mesh size, and $E^{\rm PML}$ is the PML truncation error which is exponentially small. In particular, the dependences of coefficients $C_j~(j=1,2)$ on the source $f$ are improved. Numerical experiments are presented to validate the theoretical findings, illustrating that the higher-order CIP-FEM can greatly reduce the pollution errors.","Tue, 5 Dec 2023 04:03:21 UTC (98 KB)"
"118","$\bar{B}\rightarrow \bar{D} D$ Decays and the Extraction of $f_d/f_u$ at Hadron Colliders","Jonathan Davies, Martin Jung, Stefan Schacht","High Energy Physics - Phenomenology (hep-ph)","We perform a detailed model-independent phenomenological analysis of $\bar B\to \bar D D$ decays. Employing an SU(3)$_F$ analysis including symmetry-breaking contributions together with a conservative power counting for various suppression effects, we obtain updated Standard Model predictions for all branching fractions and CP asymmetries from a fit to the available experimental data, testable at Belle II and the LHC experiments. These results include all relevant suppressed contributions, thereby providing upper limits on subleading Standard Model (SM) effects like ""penguin pollution"", enabling searches for physics beyond the SM. Importantly, allowing in the same fit for the production fractions of charged and neutral $B$ mesons to be different, we find $f_d/f_u = 0.86\pm0.05$, which is $2.5\sigma$ away from unity, which, if confirmed, would have important phenomenological consequences.","Tue, 28 Nov 2023 16:59:32 UTC (921 KB)[v2] Mon, 5 Feb 2024 09:44:46 UTC (924 KB)"
"119","Localization of a Passive Source with a Sensor Network based Experimental Molecular Communication Platform","Fatih Gulec, Damla Yagmur Koda, Baris Atakan, Andrew W. Eckford","Signal Processing (eess.SP)","In a practical molecular communication scenario such as monitoring air pollutants released from an unknown source, it is essential to estimate the location of the molecular transmitter (TX). This paper presents a novel Sensor Network-based Localization Algorithm (SNCLA) for passive transmission by using a novel experimental platform which mainly comprises a clustered sensor network (SN) with $24$ sensor nodes and evaporating ethanol molecules as the passive TX. In SNCLA, a Gaussian plume model is employed to derive the location estimator. The parameters such as transmitted mass, wind velocity, detection time, and actual concentration are calculated or estimated from the measured signals via the SN to be employed as the input for the location estimator. The numerical results show that the performance of SNCLA is better for stronger winds in the medium. Our findings show that evaporated molecules do not propagate homogeneously through the SN due to the presence of the wind. In addition, our statistical analysis based on the measured experimental data shows that the sensed signals by the SN have a log-normal distribution, while the additive noise follows a Student's t-distribution in contrast to the Gaussian assumption in the literature.","Tue, 28 Nov 2023 14:59:18 UTC (4,457 KB)"
"120","Sensitivity analysis for sets : application to pollutant concentration maps","Noé Fellmann, Mathis Pasquier, Christophette Blanchet-Scalliet, Céline Helbert, Adrien Spagnol, Delphine Sinoquet","Optimization and Control (math.OC)","In the context of air quality control, our objective is to quantify the impact of uncertain inputs such as meteorological conditions and traffic parameters on pollutant dispersion maps. It is worth noting that the majority of sensitivity analysis methods are designed to deal with scalar or vector outputs and are ill suited to a map-valued output space. To address this, we propose two classes of methods. The first technique focuses on pointwise indices. Sobol indices are calculated for each position on the map to obtain Sobol index maps. Additionally, aggregated Sobol indices are calculated. Another approach treats the maps as sets and proposes a sensitivity analysis of a set-valued output with three different types of sensitivity indices. The first ones are inspired by Sobol indices but are adapted to sets based on the theory of random sets. The second ones adapt universal indices defined for a general metric output space. The last set indices use kernel-based sensitivity indices adapted to sets. The proposed methodologies are implemented to carry out an uncertainty analysis for time-averaged concentration maps of pollutants in an urban environment in the Greater Paris area. This entails taking into account uncertain meteorological aspects, such as incoming wind speed and direction, and uncertain traffic factors, such as injected traffic volume, percentage of diesel vehicles, and speed limits on the road network.","Tue, 28 Nov 2023 14:01:05 UTC (1,808 KB)"
"121","Gaussian Processes for Monitoring Air-Quality in Kampala","Clara Stoddart, Lauren Shrack, Richard Sserunjogi, Usman Abdul-Ganiy, Engineer Bainomugisha, Deo Okure, Ruth Misener, Jose Pablo Folch, Ruby Sedgwick","Machine Learning (cs.LG)","Monitoring air pollution is of vital importance to the overall health of the population. Unfortunately, devices that can measure air quality can be expensive, and many cities in low and middle-income countries have to rely on a sparse allocation of them. In this paper, we investigate the use of Gaussian Processes for both nowcasting the current air-pollution in places where there are no sensors and forecasting the air-pollution in the future at the sensor locations. In particular, we focus on the city of Kampala in Uganda, using data from AirQo's network of sensors. We demonstrate the advantage of removing outliers, compare different kernel functions and additional inputs. We also compare two sparse approximations to allow for the large amounts of temporal data in the dataset.","Tue, 28 Nov 2023 09:25:23 UTC (3,015 KB)"
"122","Ultra-short-term multi-step wind speed prediction for wind farms based on adaptive noise reduction technology and temporal convolutional network","Haojian Huang","Machine Learning (cs.LG)","As an important clean and renewable kind of energy, wind power plays an important role in coping with energy crisis and environmental pollution. However, the volatility and intermittency of wind speed restrict the development of wind power. To improve the utilization of wind power, this study proposes a new wind speed prediction model based on data noise reduction technology, temporal convolutional network (TCN), and gated recurrent unit (GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed based on singular spectrum analysis (SSA) and Pearson correlation coefficient. The original wind speed is decomposed into multiple subsequences by SSA and then reconstructed. When the Pearson correlation coefficient between the reconstructed sequence and the original sequence is greater than 0.99, other noise subsequences are deleted to complete the data denoising. Then, the receptive field of the samples is expanded through the causal convolution and dilated convolution of TCN, and the characteristics of wind speed change are extracted. Then, the time feature information of the sequence is extracted by GRU, and then the wind speed is predicted to form the wind speed sequence prediction model of P-SSA-TCN-GRU. The proposed model was validated on three wind farms in Shandong Province. The experimental results show that the prediction performance of the proposed model is better than that of the traditional model and other models based on TCN, and the wind speed prediction of wind farms with high precision and strong stability is realized. The wind speed predictions of this model have the potential to become the data that support the operation and management of wind farms. The code is available at link.","Mon, 27 Nov 2023 03:53:19 UTC (5,086 KB)"
"123","Attacking at non-harmonic frequencies in screaming-channel attacks","Jeremy Guillaume, Maxime Pelcat, Amor Nafkha, Ruben Salvador","Cryptography and Security (cs.CR)","Screaming-channel attacks enable Electromagnetic (EM) Side-Channel Attacks (SCAs) at larger distances due to higher EM leakage energies than traditional SCAs, relaxing the requirement of close access to the victim. This attack can be mounted on devices integrating Radio Frequency (RF) modules on the same die as digital circuits, where the RF can unintentionally capture, modulate, amplify, and transmit the leakage along with legitimate signals. Leakage results from digital switching activity, so the hypothesis of previous works was that this leakage would appear at multiples of the digital clock frequency, i.e., harmonics. This work demonstrates that compromising signals appear not only at the harmonics and that leakage at non-harmonics can be exploited for successful attacks. Indeed, the transformations undergone by the leaked signal are complex due to propagation effects through the substrate and power and ground planes, so the leakage also appears at other frequencies. We first propose two methodologies to locate frequencies that contain leakage and demonstrate that it appears at non-harmonic frequencies. Then, our experimental results show that screaming-channel attacks at non-harmonic frequencies can be as successful as at harmonics when retrieving a 16-byte AES key. As the RF spectrum is polluted by interfering signals, we run experiments and show successful attacks in a more realistic, noisy environment where harmonic frequencies are contaminated by multi-path fading and interference. These attacks at non-harmonic frequencies increase the attack surface by providing attackers with an increased number of potential frequencies where attacks can succeed.","Mon, 27 Nov 2023 13:56:21 UTC (6,314 KB)"
"124","Application of Long-short Term Memory (LSTM) Model for Forecasting NOx Emission in Pohang Area","Sangdeok Lee, MinChung Kim","Applications (stat.AP)","Emissions of nitric oxide and nitrogen dioxide, which are named as NOx, are a major environmental and health this http URL react to the climate crisis, the South Korean government has strengthened NOx emission regulations. An accurate NOx prediction model can help companies to meet their NOx emission quotas and achieve cost savings. This study focuses on developing a model which forecasts the amount of NOx emissions in Pohang, a heavy industrial city in South Korea with serious air pollution this http URL this study, the Long-short term memory (LSTM) modeling is applied to predict the amount of NOx emissions, with missing data imputation using stochastic regression. Two parameters (i.e., time windows and learning rates) necessary to run the LSTM model are tested and selected using the Adam optimizer, one of the popular optimization methods in LSTM. I found that the model that I applied achieved the acceptable prediction performance since its Mean Absolute Scaled Error (MASE), the most important evaluation criterion, is less than 1. This means that applying the model that I developed in predicting future NOx emissions will perform better than a naive prediction, a model that simply predicts them based on the last observed data point.","Mon, 27 Nov 2023 08:53:21 UTC (604 KB)"
"125","Task-Distributionally Robust Data-Free Meta-Learning","Zixuan Hu, Li Shen, Zhenyi Wang, Yongxian Wei, Baoyuan Wu, Chun Yuan, Dacheng Tao","Machine Learning (cs.LG)","Data-Free Meta-Learning (DFML) aims to efficiently learn new tasks by leveraging multiple pre-trained models without requiring their original training data. Existing inversion-based DFML methods construct pseudo tasks from a learnable dataset, which is inversely generated from the pre-trained model pool. For the first time, we reveal two major challenges hindering their practical deployments: Task-Distribution Shift (TDS) and Task-Distribution Corruption (TDC). TDS leads to a biased meta-learner because of the skewed task distribution towards newly generated tasks. TDC occurs when untrusted models characterized by misleading labels or poor quality pollute the task distribution. To tackle these issues, we introduce a robust DFML framework that ensures task distributional robustness. We propose to meta-learn from a pseudo task distribution, diversified through task interpolation within a compact task-memory buffer. This approach reduces the meta-learner's overreliance on newly generated tasks by maintaining consistent performance across a broader range of interpolated memory tasks, thus ensuring its generalization for unseen tasks. Additionally, our framework seamlessly incorporates an automated model selection mechanism into the meta-training phase, parameterizing each model's reliability as a learnable weight. This is optimized with a policy gradient algorithm inspired by reinforcement learning, effectively addressing the non-differentiable challenge posed by model selection. Comprehensive experiments across various datasets demonstrate the framework's effectiveness in mitigating TDS and TDC, underscoring its potential to improve DFML in real-world scenarios.","Thu, 23 Nov 2023 15:46:54 UTC (1,201 KB)"
"126","Data-driven Prior Learning for Bayesian Optimisation","Sigrid Passano Hellan, Christopher G. Lucas, Nigel H. Goddard","Machine Learning (cs.LG)","Transfer learning for Bayesian optimisation has generally assumed a strong similarity between optimisation tasks, with at least a subset having similar optimal inputs. This assumption can reduce computational costs, but it is violated in a wide range of optimisation problems where transfer learning may nonetheless be useful. We replace this assumption with a weaker one only requiring the shape of the optimisation landscape to be similar, and analyse the recent method Prior Learning for Bayesian Optimisation - PLeBO - in this setting. By learning priors for the hyperparameters of the Gaussian process surrogate model we can better approximate the underlying function, especially for few function evaluations. We validate the learned priors and compare to a breadth of transfer learning approaches, using synthetic data and a recent air pollution optimisation problem as benchmarks. We show that PLeBO and prior transfer find good inputs in fewer evaluations.","Fri, 24 Nov 2023 18:37:52 UTC (776 KB)"
"127","GN-z11: witnessing the formation of second generation stars and an accreting massive black hole in a massive star cluster","F. D'Antona, E. Vesperini, F. Calura, P. Ventura, A. D'Ercole, V. Caloi, A. F. Marino, A. P. Milone, F. Dell'Agli, M. Tailo","Solar and Stellar Astrophysics (astro-ph.SR)","We explore the possibility that the N-rich young proto-galaxy GN-z11 recently observed at z=10.6 by the James Webb Space Telescope is the result of the formation of second generation stars from pristine gas and Asymptotic Giant Branch (AGB) ejecta in a massive globular cluster or nuclear star cluster. We show that a second generation forming out of gas polluted by the ejecta of massive AGB stars and mixed with gas having a standard composition accounts for the unusually large N/O in the GN-z11 spectrum. The timing of the evolution of massive (4-7.5M$_{\odot}$) AGBs also provides a favourable environment for the growth of a central stellar mass black hole to the Active Galactic Nucleus stage observed in GN-z11. According to our model the progenitor system was born at an age of the Universe of $\simeq 260 - 380$Myr, well within the pre-reionization epoch.","Fri, 24 Nov 2023 15:43:20 UTC (148 KB)"
"128","Seven white dwarfs with circumstellar gas discs I: white dwarf parameters and accreted planetary abundances","L. K. Rogers, A. Bonsor, S. Xu, P. Dufour, B. L. Klein, A. Buchan, S. Hodgkin, F. Hardy, M. Kissler-Patig, C. Melis, A. J. Weinberger, B. Zuckerman","Earth and Planetary Astrophysics (astro-ph.EP)","Observations of planetary material polluting the atmospheres of white dwarfs are an important probe of the bulk composition of exoplanetary material. Medium- and high-resolution optical and ultraviolet spectroscopy of seven white dwarfs with known circumstellar dust and gas emission are presented. Detections or meaningful upper limits for photospheric absorption lines are measured for: C, O, Na, S, P, Mg, Al, Si, Ca, Ti, Cr, Fe, and Ni. For 16 white dwarfs with known observable gaseous emission discs (and measured photospheric abundances), there is no evidence that their accretion rates differ, on average, from those without detectable gaseous emission. This suggests that, typically, accretion is not enhanced by gas drag. At the effective temperature range of the white dwarfs in this sample (16,000-25,000K) the abundance ratios of elements are more consistent than absolute abundances when comparing abundances derived from spectroscopic white dwarf parameters versus photometric white dwarf parameters. Crucially, this highlights that the uncertainties on white dwarf parameters do not prevent white dwarfs from being utilised to study planetary composition. The abundances of oxygen and silicon for the three hydrogen-dominated white dwarfs in the sample with both optical and ultraviolet spectra differ by 0.62 dex depending on if they are derived from the optical or ultraviolet spectra. This optical/ultraviolet discrepancy may be related to differences in the atmospheric depth of line formation; further investigations into the white dwarf atmospheric modelling are needed to understand this discrepancy.","Thu, 23 Nov 2023 15:03:21 UTC (6,816 KB)"
"129","VINCY: A Smart-contract based Data Integrity and Validation Tooling for Automated Vehicle Incident Investigation","André Budel, Reem Alhabib, Mark Nicholson, Poonam Yadav","Networking and Internet Architecture (cs.NI)","Automated Driving Systems (ADSs) are being manufactured at an accelerated rate, leading to improvements in traffic safety, reduced energy consumption, pollution, and congestion. ADS relies on various data streams from onboard sensors, external road infrastructure, and other vehicles to make driving decisions. For effective traffic accident reconstruction, investigators must produce, collect, store, and access real-time data. To ensure meaningful investigation, the data used by investigators must be accurate and maintain its integrity. In this paper, we propose a smart-contract based data integrity and validation tool for automated vehicle incident investigation during road trials, considering uncertainties in a real-world environment.","Wed, 22 Nov 2023 22:47:15 UTC (633 KB)"
"130","BenthIQ: a Transformer-Based Benthic Classification Model for Coral Restoration","Rupa Kurinchi-Vendhan, Drew Gray, Elijah Cole","Computer Vision and Pattern Recognition (cs.CV)","Coral reefs are vital for marine biodiversity, coastal protection, and supporting human livelihoods globally. However, they are increasingly threatened by mass bleaching events, pollution, and unsustainable practices with the advent of climate change. Monitoring the health of these ecosystems is crucial for effective restoration and management. Current methods for creating benthic composition maps often compromise between spatial coverage and resolution. In this paper, we introduce BenthIQ, a multi-label semantic segmentation network designed for high-precision classification of underwater substrates, including live coral, algae, rock, and sand. Although commonly deployed CNNs are limited in learning long-range semantic information, transformer-based models have recently achieved state-of-the-art performance in vision tasks such as object detection and image classification. We integrate the hierarchical Swin Transformer as the backbone of a U-shaped encoder-decoder architecture for local-global semantic feature learning. Using a real-world case study in French Polynesia, we demonstrate that our approach outperforms traditional CNN and attention-based models on pixel-wise classification of shallow reef imagery.","Wed, 22 Nov 2023 19:25:31 UTC (2,862 KB)"
"131","Spacecraft Coatings Optimizing LiDAR Debris Tracking and Light Pollution Impacts","Julia Hudson, Eric Jones","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Space safety and astronomy are at odds. The problem posed by space debris and derelict satellites in the low Earth orbit is an existential threat to all space operations. These dangerous objects in space are more easily tracked with ground-based LiDAR if they are highly reflective, especially in the near-infrared (NIR) range. At the same time, reflective objects in orbit are the bane of ground-based astronomers, causing light pollution and marring images with bright streaks. How can this tension be resolved? The hypothesis tested is that a near-infrared-transparent (NIRT) coating which is opaque in the visible light range and transparent in the NIR range is a promising candidate for use in satellite construction. This experiment tests whether typical spacecraft surfaces such as anodized aluminum or multi-layer insulation (MLI) with a NIRT coating applied will absorb visible light and reflect NIR. The findings confirm the efficacy of the NIRT coating for this purpose, reducing visible light reflection by 47% (+/-3%) and increasing reflection in the NIR by 7% (+/-2%). This promising novel NIRT coating may help provide a path forward to resolve the tension between astronomy and the space industry.","Wed, 22 Nov 2023 02:22:55 UTC (1,354 KB)"
"132","Speed limits in traffic emission models using multi-objective optimization","Simone Göttlich, Michael Herty, Alena Ulke","Optimization and Control (math.OC)","Climate change compels a reduction of greenhouse gas emissions, yet vehicular traffic still contributes significantly to the emission of air pollutants. Hence, in this paper we focus on the optimization of traffic flow while simultaneously minimizing air pollution using speed limits as controllable parameters. We introduce a framework of traffic emission models to simulate the traffic dynamic as well as the production and spread of air pollutants. We formulate a multi-objective optimization problem for the optimization of multiple aspects of vehicular traffic. The results show that multi-objective optimization can be a valuable tool in traffic emission modeling as it allows to find optimal compromises between ecological and economic objectives.","Tue, 21 Nov 2023 17:32:13 UTC (57 KB)"
"133","Spatio-Temporal Modeling of Surface Water Quality Distribution in California (1956-2023)","Houlin Chen, Meredith Franklin","Applications (stat.AP)","Surface water quality has a direct impact on public health, ecosystems, and agriculture, in addition to being an important indicator of the overall health of the environment. California's diverse climate, extensive coastline, and varied topography lead to distinct spatial and temporal patterns in surface water. This study offers a comprehensive assessment of these patterns by leveraging around 70 years of data, taking into account climate zones and geographical types. We analyzed surface water quality indicators, including pH, dissolved oxygen, specific conductance, and water temperature, based on field results from approximately 5,000 water quality stations in California Water Quality Data (CWQD). Machine learning (ML) models were developed to establish relationships between spatial and temporal variables, climate zones, geographical types, and water quality indicators. Applying these models to spatially interpolate and temporally predict the four water quality indicators over California for the next 50 years, the research results indicate an uneven distribution of water quality indicators in California, suggesting the presence of potential pollution zones, seawater erosion, and effects of climate change.","Tue, 21 Nov 2023 17:21:45 UTC (10,384 KB)"
"134","Sensitivity analysis with multiple treatments and multiple outcomes with applications to air pollution mixtures","Suyeon Kang, Alexander Franks, Joseph Antonelli","Methodology (stat.ME)","Understanding the health impacts of air pollution is vital in public health research. Numerous studies have estimated negative health effects of a variety of pollutants, but accurately gauging these impacts remains challenging due to the potential for unmeasured confounding bias that is ubiquitous in observational studies. In this study, we develop a framework for sensitivity analysis in settings with both multiple treatments and multiple outcomes simultaneously. This setting is of particular interest because one can identify the strength of association between the unmeasured confounders and both the treatment and outcome, under a factor confounding assumption. This provides informative bounds on the causal effect leading to partial identification regions for the effects of multivariate treatments that account for the maximum possible bias from unmeasured confounding. We also show that when negative controls are available, we are able to refine the partial identification regions substantially, and in certain cases, even identify the causal effect in the presence of unmeasured confounding. We derive partial identification regions for general estimands in this setting, and develop a novel computational approach to finding these regions.","Tue, 21 Nov 2023 00:19:25 UTC (64 KB)"
"135","Multifractal characterisation of particulate matter (PM10) time series in the Caribbean basin using visibility graphs","T. Plocoste, R. Carmona-Cabezas, F.J. Jimenez-Hornero, E. Gutierrez de Rave, R. Calif","Atmospheric and Oceanic Physics (physics.ao-ph)","A good knowledge of pollutant time series behavior is fundamental to elaborate strategies and construct tools to protect human health. In Caribbean area, air quality is frequently deteriorated by the transport of African dust. In the literature, it is well known that exposure to particulate matter with an aerodynamic diameter of 10 {\mu}m or less (PM10) have many adverse health effects as respiratory and cardiovascular diseases. To our knowledge, no study has yet performed an analysis of PM10 time series using complex network framework. In this study, the so-called Visibility Graph (VG) method is used to describe PM10 dynamics in Guadeloupe archipelago with a database of 11 years. Firstly, the fractal nature of PM10 time series is highlighted using degree distribution for all data, low dust season (October to April) and high dust season (May to September). Thereafter, a profound description of PM10 time series dynamics is made using multifractal analysis through two approaches, i.e. Renyi and singularity spectra. Achieved results are consistent with PM10 behavior in the Caribbean basin. Both methods showed a higher multifractality degree during the low dust season. In addition, multifractal parameters exhibited that the low dust season has the higher recurrence and the lower uniformity degrees. Lastly, centrality measures (degree, closeness and betweenness) highlighted PM10 dynamics through the year with a decay of centrality values during the high dust season. To conclude, all these results clearly showed that VG is a robust tool to describe times series properties.","Sun, 19 Nov 2023 20:51:30 UTC (1,230 KB)"
"136","Wet scavenging process of particulate matter (PM10): A multivariate complex network approach","T. Plocoste, R. Carmona-Cabezas, E. Gutierrez de Rave, F.J. Jimenez-Hornero","Atmospheric and Oceanic Physics (physics.ao-ph)","This paper reports the results of research on PM10 wet scavenging by rainfall using a new multilayer complex networks called Multiplex Visibility Graphs (MVG). To the best of our knowledge, this work is the first to assess PM10 wet deposition using multivariate time series according to African dust seasonality. We considered 11 years of daily PM10 and rainfall data from the Guadeloupe archipelago. To analyse the impact of rainfall on PM10 behaviour, two MVG parameters were computed: the average edge overlap ({\omega}) and the interlayer mutual information (IPM). On the 1-d scale, the {\omega} results showed that the wet scavenging process was higher during the second half of the year when the high dust season and the rainy season are juxtaposed. This highlights a greater correlation between the microscopic structure of the signal, and the impact of rainfall on PM10 concentrations is more significant when the atmosphere is loaded with dust. The joint probability computed between the PM10 and rainfall nodes confirmed this trend. The IPM results indicated a correlation between PM10 and rainfall structures throughout the year. Furthermore, IPM values were higher during the transition periods between winter and summer (and vice versa). Our study showed that MVG is a powerful technique for investigating the relationship between at least two nonlinear time series using a multivariate time series.","Sat, 18 Nov 2023 12:21:51 UTC (472 KB)"
"137","6G Fresnel Spot Beamfocusing using Large-Scale Metasurfaces: A Distributed DRL-Based Approach","Mehdi Monemi, Mohammad Amir Fallah, Mehdi Rasti, Matti Latva-Aho","Systems and Control (eess.SY)","In this paper, we introduce the concept of spot beamfocusing (SBF) in the Fresnel zone through extremely large-scale programmable metasurfaces (ELPMs) as a key enabling technology for 6G networks. A smart SBF scheme aims to adaptively concentrate the aperture's radiating power exactly at a desired focal point (DFP) in the 3D space utilizing some Machine Learning (ML) method. This offers numerous advantages for next-generation networks including efficient wireless power transfer (WPT), interference mitigation, reduced RF pollution, and improved information security. SBF necessitates ELPMs with precise channel state information (CSI) for all ELPM elements. However, obtaining exact CSI for ELPMs is not feasible in all environments; we alleviate this by proposing an adaptive novel CSI-independent ML scheme based on the TD3 deep-reinforcement-learning (DRL) method. While the proposed ML-based scheme is well-suited for relatively small-size arrays, the computational complexity is unaffordable for ELPMs. To overcome this limitation, we introduce a modular highly scalable structure composed of multiple sub-arrays, each equipped with a TD3-DRL optimizer. This setup enables collaborative optimization of the radiated power at the DFP, significantly reducing computational complexity while enhancing learning speed. The proposed structures benefits in terms of 3D spot-like power distribution, convergence rate, and scalability are validated through simulation results.","Sat, 18 Nov 2023 15:50:41 UTC (3,386 KB)"
"138","Multiplex Visibility Graphs as a complementary tool for describing the relation between ground level O3 and NO2","R. Carmona-Cabezas, J. Gomez-Gomez, A.B. Ariza-Villaverde, E. Gutierrez de Rave, F.J. Jimenez-Hornero","Atmospheric and Oceanic Physics (physics.ao-ph)","The usage of multilayer complex networks for the analysis of correlations among environmental variables (such as O3 and NO2 concentrations from the photochemical smog) is investigated in this work. The mentioned technique is called Multiplex Visibility Graphs (MVG). By performing the joint analysis of those layers, the parameters named Average Edge Overlap and Interlayer Mutual Information are extracted, which accounts for the microscopical time coherence and the correlation between the time series behavior, respectively. These parameters point to the possibility of using them independently to describe the correlation between atmospheric pollutants (which could be extended to environmental time series). More precisely the first one of them is considered to be a potential new approach to determine the time required for the correlation of NO2 and O3 to be observed, since it is obtained from the correlation of the pollutants at the smallest time scale. As for the second one, it has been checked that the proposed technique can be used to describe the variation of the correlation between the two gases along the seasons. In short, MVGs parameters are introduced and results show that they could be potentially used in a future for correlation studies, supplementing already existing techniques.","Sat, 18 Nov 2023 07:02:41 UTC (1,244 KB)"
"139","Checking complex networks indicators in search of singular episodes of the photochemical smog","R. Carmona-Cabezas, J. Gomez-Gomez, E. Gutierrez de Rave, F.J. Jimenez-Hornero","Atmospheric and Oceanic Physics (physics.ao-ph)","A set of indicators derived from the analysis of complex networks have been introduced to identify singularities on a time series. To that end, the Visibility Graphs (VG) from three different signals related to photochemical smog (O3, NO2 concentration and temperature) have been computed. From the resulting complex network, the centrality parameters have been obtained and compared among them. Besides, they have been contrasted to two others that arise from a multifractal point of view, that have been widely used for singularity detection in many fields: the Holder and singularity exponents (specially the first one of them). The outcomes show that the complex network indicators give equivalent results to those already tested, even exhibiting some advantages such as the unambiguity and the more selective results. This suggest a favorable position as supplementary sources of information when detecting singularities in several environmental variables, such as pollutant concentration or temperature.","Sat, 18 Nov 2023 06:49:40 UTC (1,270 KB)"
"140","Can complex networks describe the urban and rural tropospheric O3 dynamics?","R. Carmona-Cabezas, J. Gomez-Gomez, A.B. Ariza-Villaverde, E. Gutierrez de Rave, F.J. Jimenez-Hornero","Physics and Society (physics.soc-ph)","Tropospheric ozone (O3) time series have been converted into complex networks through the recent so-called Visibility Graph (VG), using the data from air quality stations located in the western part of Andalusia (Spain). The aim is to apply this novel method to differentiate the behavior between rural and urban regions when it comes to the ozone dynamics. To do so, some centrality parameters of the resulting complex networks have been investigated: the degree, betweenness and shortest path. Some of them are expected to corroborate previous works in order to support the use of this technique; while others to supply new information. Results coincide when describing the difference that tropospheric ozone exhibits seasonally and geographically. It is seen that ozone behavior is fractal, in accordance to previous works. Also, it has been demonstrated that this methodology is able to characterize the divergence encountered between measurements in urban environments and countryside. In addition to that, the promising outcomes of this technique support the use of complex networks for the study of air pollutants dynamics. Particularly, new nuances are offered such as the identification and description of singularities in the signal.","Thu, 16 Nov 2023 20:15:07 UTC (992 KB)"
"141","Multi-Objective Transmission Expansion: An Offshore Wind Power Integration Case Study","Saroj Khanal, Christoph Graf, Zhirui Liang, Yury Dvorkin, Burçin Ünel","Systems and Control (eess.SY)","Despite ambitious offshore wind targets in the U.S. and globally, offshore grid planning guidance remains notably scarce, contrasting with well-established frameworks for onshore grids. This gap, alongside the increasing penetration of offshore wind and other clean-energy resources in onshore grids, highlights the urgent need for a coordinated planning framework. Our paper describes a multi-objective, multistage generation, storage and transmission expansion planning model to facilitate efficient and resilient large-scale adoption of offshore wind power. Recognizing regulatory emphasis, in some cases, requirements to consider externalities, this model explicitly accounts for negative externalities: greenhouse gas emissions and local emission-induced air pollution. Utilizing an 8-zone ISO-NE test system and a 9-zone PJM test system, we explore grid expansion sensitivities, onshore and offshore, due to offshore wind integration, including impacts of optimizing Points of Interconnection (POIs) versus fixed POIs, negative externalities, and consideration of extreme operational scenarios. Our results indicate that accounting for negative externalities necessitates greater upfront investment in clean generation and storage (balanced by lower expected operational costs) and less offshore investment. Optimizing POIs could significantly reshape offshore topology or POIs and lower total cost, albeit requiring more onshore transmission. Extreme operational scenarios typically result in greater operational costs and onshore line investment.","Thu, 16 Nov 2023 04:53:39 UTC (6,739 KB)[v2] Mon, 4 Mar 2024 17:26:28 UTC (22,216 KB)"
"142","Developing a Novel Holistic, Personalized Dementia Risk Prediction Model via Integration of Machine Learning and Network Systems Biology Approaches","Srilekha Mamidala","Neurons and Cognition (q-bio.NC)","The prevalence of dementia has increased over time as global life expectancy improves and populations age. An individual's risk of developing dementia is influenced by various genetic, lifestyle, and environmental factors, among others. Predicting dementia risk may enable individuals to employ mitigation strategies or lifestyle changes to delay dementia onset. Current computational approaches to dementia prediction only return risk upon narrow categories of variables and do not account for interactions between different risk variables. The proposed framework utilizes a novel holistic approach to dementia risk prediction and is the first to incorporate various sources of tabular environmental pollution and lifestyle factor data with network systems biology-based genetic data. LightGBM gradient boosting was employed to ensure validity of included factors. This approach successfully models interactions between variables through an original weighted integration method coined Sysable. Multiple machine learning models trained the algorithm to reduce reliance on a single model. The developed approach surpassed all existing dementia risk prediction approaches, with a sensitivity of 85%, specificity of 99%, geometric accuracy of 92%, and AUROC of 91.7%. A transfer learning model was implemented as well. De-biasing algorithms were run on the model via the AI Fairness 360 Library. Effects of demographic disparities on dementia prevalence were analyzed to potentially highlight areas in need and promote equitable and accessible care. The resulting model was additionally integrated into a user-friendly app providing holistic predictions and personalized risk mitigation strategies. The developed model successfully employs holistic computational dementia risk prediction for clinical use.","Wed, 4 Oct 2023 02:47:29 UTC (2,852 KB)[v2] Wed, 10 Jan 2024 21:08:59 UTC (4,148 KB)"
"143","EMF-Aware Power Control for Massive MIMO: Cell-Free versus Cellular Networks","Sergi Liesegang, Stefano Buzzi","Information Theory (cs.IT)","The impressive growth of wireless data networks has recently led to increased attention to the issue of electromagnetic pollution. Specific absorption rates and incident power densities have become popular indicators for measuring electromagnetic field (EMF) exposure. This paper tackles the problem of power control in user-centric cell-free massive multiple-input-multiple-output (CF-mMIMO) systems under EMF constraints. Specifically, the power allocation maximizing the minimum data rate across users is derived for both the uplink and the downlink under EMF constraints. The developed solution is also applied to a cellular mMIMO system and compared to other benchmark strategies. Simulation results prove that EMF safety restrictions can be easily met without jeopardizing the minimum data rate, that the CF-mMIMO outperforms the multi-cell massive MIMO deployment, and that the proposed power control strategy greatly improves the system fairness.","Wed, 15 Nov 2023 14:22:21 UTC (715 KB)"
"144","A Hybrid Approach using ARIMA, Kalman Filter and LSTM for Accurate Wind Speed Forecasting","Manas Ranjan Mohapatra, Rahul Radhakrishnan, Raj Mani Shukla","Systems and Control (eess.SY)","Present energy demand and modernization are leading to greater fossil fuel consumption, which has increased environmental pollution and led to climate change. Hence to decrease dependency on conventional energy sources, renewable energy sources are considered. Wind energy is a long-term renewable energy resource but its intermittent nature makes it difficult in harnessing it. Since wind speed prediction is vital there are different methodologies for wind speed estimation available in the literature. In this work, a new hybrid model is proposed by combining auto-regressive integrated moving average (ARIMA), Kalman filter and long short-term memory (LSTM) for estimating wind speed which works more accurately than the existing methods proposed in the literature. From simulations, it is observed that the proposed method works with better accuracy when compared to the existing methods.","Tue, 14 Nov 2023 21:22:52 UTC (5,401 KB)[v2] Thu, 16 Nov 2023 23:31:31 UTC (1 KB) (withdrawn)"
"145","A cool, magnetic white dwarf accreting planetary debris","Stephane Vennes, Adela Kawka, Beth L. Klein, B. Zuckerman, Alycia J. Weinberger, Carl Melis","Solar and Stellar Astrophysics (astro-ph.SR)","We present an analysis of spectroscopic data of the cool, highly magnetic and polluted white dwarf 2MASS J0916-4215. The atmosphere of the white dwarf is dominated by hydrogen, but numerous spectral lines of magnesium, calcium, titanium, chromium, iron, strontium, along with Li I, Na I, Al I, and K I lines, are found in the incomplete Paschen-Back regime, most visibly, in the case of Ca II lines. Extensive new calculations of the Paschen-Back effect in several spectral lines are presented and results of the calculations are tabulated for the Ca II H&K doublet. The abundance pattern shows a large lithium and strontium excess, which may be viewed as a signature of planetary debris akin to Earth's continental crust accreted onto the star, although the scarcity of silicon indicates possible dilution in bulk Earth material. Accurate abundance measurements proved sensitive to the value of the broadening parameter due to collisions with neutral hydrogen (Gamma_HI), particularly in saturated lines such as the resonance lines of Ca I and Ca II. We found that Gamma_HI if formulated with values from the literature could be overestimated by a factor of 10 in most resonance lines.","Tue, 14 Nov 2023 06:29:04 UTC (1,380 KB)"
"146","Simulating Public Administration Crisis: A Novel Generative Agent-Based Simulation System to Lower Technology Barriers in Social Science Research","Bushi Xiao, Ziyuan Yin, Zixuan Shan","Computers and Society (cs.CY)","This article proposes a social simulation paradigm based on the GPT-3.5 large language model. It involves constructing Generative Agents that emulate human cognition, memory, and decision-making frameworks, along with establishing a virtual social system capable of stable operation and an insertion mechanism for standardized public events. The project focuses on simulating a township water pollution incident, enabling the comprehensive examination of a virtual government's response to a specific public administration event. Controlled variable experiments demonstrate that the stored memory in generative agents significantly influences both individual decision-making and social networks. The Generative Agent-Based Simulation System introduces a novel approach to social science and public administration research. Agents exhibit personalized customization, and public events are seamlessly incorporated through natural language processing. Its high flexibility and extensive social interaction render it highly applicable in social science investigations. The system effectively reduces the complexity associated with building intricate social simulations while enhancing its interpretability.","Sun, 12 Nov 2023 20:48:01 UTC (2,238 KB)"
"147","Friction Tubes to Generate Nanobubble Ozone Water with an Increased Half-Life for Virucidal Activity","Suk-Joo Byun, A-Ram You, Tae Seok Park, Chang-Hee Park, Dae-Hyun Choi, Eun-Hee Jun, Young-Ho Yoo, Taekeun Yoo","Fluid Dynamics (physics.flu-dyn)","Nanobubbles and related technologies are expected to be highly utilized in water resource-based industries such as water purification, crops, horticulture, medicine, bio, and sterilization. Ozone, a chemical with high sterilizing power, is known as a natural substance that is reduced to oxygen and water after reacting with pollutants. Ozone water, which is generated by dissolving ozone in water, has been used in various industrial sectors such as medical care, food, and environment. Due to the unstable molecular state of ozone, however, it is difficult to produce, use, and supply ozone at industrial sites in a stable manner. This study proposed a method for constructing a system that can generate high-concentration ozone water in large quantities using low power in real time and maintaining the concentration of the generated ozone water over the long term. Friction tubes (called 'nanotube') played a key role to generate nanobubble ozone water with an increased half-life for virus killing activity. In addition, the safety of ozone water during its spray into the air was explained, and virucidal activity test cases for the influenza A (H1N1/A/PR8) and COVID-19 (SARS-CoV-2) virus using high-concentration ozone water as well as its technical efficacy were described.","Sun, 12 Nov 2023 20:11:18 UTC (818 KB)"
"148","Structure of liquid--vapor interfaces: perspectives from liquid state theory, large-scale simulations, and potential grazing-incidence X-ray diffraction","Felix Höfling, Siegfried Dietrich","Soft Condensed Matter (cond-mat.soft)","Grazing-incidence X-ray diffraction (GIXRD) is a scattering technique which allows one to characterize the structure of fluid interfaces down to the molecular scale, including the measurement of the surface tension and of the interface roughness. However, the corresponding standard data analysis at non-zero wave numbers has been criticized as to be inconclusive because the scattering intensity is polluted by the unavoidable scattering from the bulk. Here we overcome this ambiguity by proposing a physically consistent model of the bulk contribution which is based on a minimal set of assumptions of experimental relevance. To this end, we derive an explicit integral expression for the background scattering, which can be determined numerically from the static structure factors of the coexisting bulk phases as independent input. Concerning the interpretation of GIXRD data inferred from computer simulations, we account also for the finite sizes of the bulk phases, which are unavoidable in simulations. The corresponding leading-order correction beyond the dominant contribution to the scattered intensity is revealed by asymptotic analysis, which is characterized by the competition between the linear system size and the X-ray penetration depth in the case of simulations. Specifically, we have calculated the expected GIXRD intensity for scattering at the planar liquid--vapor interface of Lennard-Jones fluids with truncated pair interactions via extensive, high-precision simulations. The reported data cover interfacial and bulk properties of fluid states along the whole liquid--vapor coexistence line. A sensitivity analysis demonstrates the robustness of our findings concerning the detailed definition of the mean interface position. We conclude that previous claims of an enhanced surface tension at mesoscopic scales are amenable to unambiguous tests via scattering experiments.","Fri, 10 Nov 2023 23:23:52 UTC (6,171 KB)[v2] Sat, 10 Feb 2024 15:59:19 UTC (6,510 KB)"
"149","Mobile Internet Quality Estimation using Self-Tuning Kernel Regression","Hanyang Jiang, Henry Shaowu Yuchi, Elizabeth Belding, Ellen Zegura, Yao Xie","Applications (stat.AP)","Modeling and estimation for spatial data are ubiquitous in real life, frequently appearing in weather forecasting, pollution detection, and agriculture. Spatial data analysis often involves processing datasets of enormous scale. In this work, we focus on large-scale internet-quality open datasets from Ookla. We look into estimating mobile (cellular) internet quality at the scale of a state in the United States. In particular, we aim to conduct estimation based on highly {\it imbalanced} data: Most of the samples are concentrated in limited areas, while very few are available in the rest, posing significant challenges to modeling efforts. We propose a new adaptive kernel regression approach that employs self-tuning kernels to alleviate the adverse effects of data imbalance in this problem. Through comparative experimentation on two distinct mobile network measurement datasets, we demonstrate that the proposed self-tuning kernel regression method produces more accurate predictions, with the potential to be applied in other applications.","Sat, 4 Nov 2023 21:09:46 UTC (7,907 KB)"
"150","Automated transient detection in the context of the 4m ILMT","Kumar Pranshu, Bhavya Ailawadhi, Talat Akhunov, Ermanno Borra, Monalisa Dubey, Naveen Dukiya, Jiuyang Fu, Baldeep Grewal, Paul Hickson, Brajesh Kumar, Kuntal Misra, Vibhore Negi, Ethen Sun, Jean Surdej","Instrumentation and Methods for Astrophysics (astro-ph.IM)","In the era of sky surveys like Palomar Transient Factory (PTF), Zwicky Transient Facility (ZTF) and the upcoming Vera Rubin Observatory (VRO) and ILMT, a plethora of image data will be available. ZTF scans the sky with a field of view of 48 deg$^{2}$ and VRO will have a FoV of 9.6 deg$^{2}$ but with a much larger aperture. The 4m ILMT covers a 22$'$ wide strip of the sky. Being a zenith telescope, ILMT has several advantages like low observation air mass, best image quality, minimum light pollution and no pointing time loss. Transient detection requires all these imaging data to be processed through a Difference Imaging Algorithm (DIA) followed by subsequent identification and classification of transients. The ILMT is also expected to discover several known and unknown astrophysical objects including transients. Here, we propose a pipeline with an image subtraction algorithm and a convolutional neural network (CNN) based automated transient discovery and classification system. The pipeline was tested on ILMT data and the transients as well as variable candidates were recovered and classified.","Wed, 8 Nov 2023 14:42:02 UTC (7,130 KB)"
