---
title: "Activity 3"
author: "Randell Eduarth Soteo"
date: "2024-02-13"
---
  
```{r }
# Install and load required packages
install.packages("rvest")
install.packages("httr")
install.packages("polite")
```

```{r}

library(rvest)
library(httr)
library(polite)
```

```{r}
# Set up polite scraper
polite::use_manners(save_as = 'polite_scrape.R')
```

```{r}
# Define the URL template
url_template <- 'https://www.imdb.com/title/tt0108052/reviews/_ajax?ref_=undefined&paginationKey=%s'
```

```{r}
# Function to scrape data from a single page
scrape_page <- function(url_template, pagination_key) {
  session <- bow(sprintf(url_template, pagination_key), user_agent = "Educational")
  
  # Scrape data
  Usernames <- scrape(session) %>% html_nodes('span.display-name-link') %>% html_text()
  ReviewerDates <- scrape(session) %>% html_nodes('span.review-date') %>% html_text()
  ReviewerContents <- scrape(session) %>% html_nodes('div.text.show-more__control') %>% html_text()
  Ratings <- scrape(session) %>% html_nodes('span.rating-other-user-rating') %>% html_text()
  
  # Extract pagination key for the next page
  pagination_key <- scrape(session) %>% html_nodes("div.load-more-data") %>% html_attr("data-key")
  
  return(list(Usernames = Usernames, ReviewerDates = ReviewerDates, ReviewerContents = ReviewerContents, Ratings = Ratings, pagination_key = pagination_key))
}
```

```{r}
# Initialize vectors
Usernames <- character(0)
ReviewerDates <- character(0)
ReviewerContents <- character(0)
Ratings <- character(0)
pagination_key <- ""
```

```{r}
# Scrape data from multiple pages
reviews_to_scrape <- 300
per_page <- 25
pages_to_scrape <- ceiling(reviews_to_scrape / per_page)
```

```{r}
for (page in 1:pages_to_scrape) {
  scraped_data <- scrape_page(url_template, pagination_key)
  
  Usernames <- c(Usernames, scraped_data$Usernames)
  ReviewerDates <- c(ReviewerDates, scraped_data$ReviewerDates)
  ReviewerContents <- c(ReviewerContents, scraped_data$ReviewerContents)
  Ratings <- c(Ratings, scraped_data$Ratings)
  
  pagination_key <- scraped_data$pagination_key
  
  # Check if we have reached the desired number of reviews
  if (length(Usernames) >= reviews_to_scrape) {
    break
  }
}
```

```{r}
# Create a data frame
DataFrame <- data.frame(
  Usernames = Usernames[1:300],
  Reviewer_Date = ReviewerDates[1:300],
  Reviewer_Content = ReviewerContents[1:300],
  Rating = Ratings[1:300]
)
```

```{r}
# Save as CSV
write.csv(DataFrame, file = "6_imdb_reviews.csv", row.names = FALSE)
```

```{r}
# Print the data frame
print(DataFrame)
```